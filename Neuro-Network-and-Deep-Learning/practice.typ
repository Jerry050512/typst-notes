#import "../template/conf.typ": conf
#import "../template/components.typ": *

#show: conf.with(
  title: [
    深度学习与神经网络 习题
  ],
  authors: (
    (
      name: [Gang.],
      affiliation: [Hangzhou Dianzi University],
      email: "jerry050512@outlook.com",
    ),
  )
)

#set figure(
  numbering: none
)

= 往年真题

来源: #link("https://zhuanlan.zhihu.com/p/606945292")[知乎: 2023HDU深度学习考试试题及复习重点], #link("https://zhuanlan.zhihu.com/p/455025127")[知乎: 2021-2022题目]

== 选择

1.  (多选) 人工智能的主要领域可分为【 】\
  A.感知 B.学习 C.认知 D.以上都不对
2.  (多选) 关于轴突和树突下列正确的是【 】\
  A.轴突可以有多个 \
  B.树突可以有多个 \
  C.树突可以接受刺激传递兴奋 \
  D.轴突可以传递兴奋
3. 下列关于第L层神经元的计算正确的是【 】 \
  A.先计算上一层的净活性值, 再计算出第L层的活性值 \
  B.计算上一层的净活性值的平均值, 再计算出第L层的活性值 \
  C.先计算上一层的活性值, 再计算出第L层的净活性值 \
  D.以上都不对 \
  #emoji.key 净活性值也称净输入值. 
4.  (给了一张图) 求前馈神经网络隐藏层的某一层的W和B的维度. 
5. 给了卷积核的尺寸, 填充和步长等信息, 计算卷积后的特征尺寸. 例如, 在一个卷积神经网络中, 某层的输入特征图尺寸为 $32 times 32$. 现使用一个尺寸为 $5 times 5$ 的卷积核进行卷积运算. 已知该层的步长 (Stride) 设置为 2, 零填充 (Padding) 设置为 2.  请计算该层输出的特征图尺寸.  \
  #emoji.key $ floor((M + 2P - K) / S) + 1 $
6.  (多选) 卷积的三个特性是【 】 \
  A.局部连接 B.权重共享 C.局部不变 D.汇聚
7. 下列适用于词性标注的是【 】 \
  A.卷积神经网络 \
  B.前馈神经网络 \
  C.循环神经网络 \
  D.神经图灵机
8. 下列属于批量归一化的优点的是【 】\
  A. 统计量的计算仅取决于当前单个样本, 完全不依赖批量 (Batch) 的大小 \
  B. 在处理变长序列的循环神经网络 (RNN) 中表现出卓越的稳定性 \
  C. 训练时通过小批量的均值和方差引入随机噪声, 具有一定的正则化效果 \
  D. 测试阶段无需记录训练时的全局统计量, 直接计算当前层输出即可 \
  #emoji.key *层归一化 (LN) *在处理变长序列数据时表现更稳定
9. 神经图灵机和端到端神经网络的区别【】 \
  A.只读; 读写 \
  B.读写; 只读 \
  C.都只只读 \
  D.都能读写
10.  (多选) 下列属于参数密度估计会遇到的问题是【 】\
  A.模型选择问题 \
  B.不可观测变量问题 \
  C.维度灾难问题 \
  D.核函数的宽度选择困难 \
  #emoji.key 核函数和窗方法是非参数密度估计. 
11. 相比长短期记忆网络 (LSTM), 门控循环单元 (GRU) 的结构更加精简, 它主要包含哪两个门? 【 】 \
  A. 输入门 (Input Gate)、遗忘门 (Forget Gate) \
  B. 重置门 (Reset Gate)、更新门 (Update Gate) \
  C. 输入门 (Input Gate)、输出门 (Output Gate) \
  D. 遗忘门 (Forget Gate)、重置门 (Reset Gate) \
12. 在小批量梯度下降算法的单次迭代中, 正确的参数更新操作顺序是【 】 \
  ① 随机初始化参数 θ \
  ② 将训练集随机打乱 (Shuffle) \
  ③ 计算该小批量的平均梯度 \
  ④ 更新参数 θ \
  ⑤ 选取一个包含 K 个样本的小集合 (Mini-batch) \
  A. ①→②→③→④→⑤ \
  B. ②→①→⑤→③→④ \
  C. ①→②→⑤→③→④ \
  D. ①→⑤→②→④→③
13. 某卷积层输入通道数为 3, 输出通道数为 16, 卷积核尺寸为 $3 times 3$. 若考虑偏置项, 该层可学习的参数总数为【 】\
  A. 144 \
  B. 432 \
  C. 448 \
  D. 48 \
  #emoji.key $ (U times V) times D times P + P $
14. 下列哪种模型通常不被归类为深度学习模型? 【 】 \
  A. 卷积神经网络 (CNN) \
  B. 循环神经网络 (RNN) \
  C. 单层感知器 (Perceptron) \
  D. 深度信念网络 (DBN)
15. 超参数是定义模型结构和训练算法的参数, 无法通过梯度下降自动更新. 下列属于超参数的是【 】 \
  A. 连接权重矩阵 W \
  B. 偏置向量 b \
  C. 学习率 α 与正则化系数 λ \
  D. 神经元的活性值 a
16. 在自然语言处理任务 (如词性标注) 中, 通常选择循环神经网络 (RNN) 而非前馈网络的主要原因是【 】 \
  A. RNN 的计算复杂度更低, 训练速度更快 \
  B. 一个词的词性通常由上下文决定, RNN 能够捕捉序列的顺序依赖性 \
  C. RNN 只能处理长度固定的序列, 符合分词要求 \
  D. RNN 的参数在所有时间步是不共享的, 表达能力更强 \

*Answer Sheet*
#table(
  columns: 11, 
  fill: (x, y) => if (calc.even(y)) {luma(80%)},
  [*Number*], [*1*], [*2*], [*3*], [*4*], [*5*], [*6*], [*7*], [*8*], [*9*], [*10*],
  [*Answer*], [ABC], [BCD], [C], [], [$16 times 16$], [ABD], [C], [C], [B], [ABC], 
  [*Number*], [*11*], [*12*], [*13*], [*14*], [*15*], [*16*], [*17*], [*18*], [*19*], [*20*],
  [*Answer*], [B], [C], [C], [C], [C], [B]
)

== 简答题

1.  (5分) 人工智能, 机器学习, 深度学习和神经网络的区别和联系是什么? 

人工智能、机器学习、深度学习和神经网络之间存在着层层递进的包含关系与密切的技术联系. 从范围上看, *人工智能 (AI) 是最宽泛的概念, 其目标是让机器具有人类的智能*. *机器学习 (ML) 是实现人工智能的一种重要子领域, 指从有限的观测数据中通过算法总结出一般性规律, 并利用这些规律对未知数据进行预测的方法*.  \
*深度学习 (DL) 则是机器学习的一个子集, 其核心在于通过多步非线性特征转换 (即“深度”模型) 自动从原始数据中学习有效的特征表示*. 深度学习与传统机器学习的主要区别在于, 传统方法通常需要人工经验进行特征提取和转换 (特征工程), 而深度学习通过端到端学习, 让模型自动跨越“语义鸿沟”, 直接从底层特征学习到高层语义表示.  \
*神经网络 (NN) 是深度学习最主要的模型载体*. 它受人脑神经系统启发, 由大量人工神经元构成, 通过调整神经元之间的连接权重来存储知识. *神经网络和深度学习并不完全等价*, 但由于神经网络能够通过误差反向传播算法较好地解决“贡献度分配问题” (即确定各参数对输出结果的影响), 它成为了深度学习中主要采用的模型. 当一个神经网络具备多层结构 (通常超过两层) 时, 其学习过程即可被视作深度学习.  \
总结而言, 人工智能是远景目标, 机器学习是实现手段, 深度学习是其中一种通过模拟多层抽象来实现自动特征学习的高级范式, 而神经网络则是支撑深度学习最核心的数学模型与架构. 

2.  (6分) 激活函数需要具有哪些性质? 

为了增强神经网络的表示和学习能力, 激活函数通常需要具备以下性质: 
+ 首先, 激活函数应是*连续可导的非线性函数*, 非线性性质能增强网络的表示能力, 而可导性则允许模型利用数值优化的方法来学习参数. 
+ 其次, *激活函数及其导函数的形式应尽可能简单*, 这有利于提高网络整体的计算效率. 
+ 最后, 激活函数导函数的值域需要在*一个合适的区间内*, 避免因过大或过小而影响模型训练的效率和稳定性. 

3. 对于循环神经网络, 不采用门控机制, 如何改进? 

对于循环神经网络 (RNN), 若不采用门控机制, 主要通过*优化训练策略、参数初始化以及改进网络结构*来缓解长程依赖中的*梯度消失和爆炸问题*.  \
针对梯度爆炸, 最有效的方法是采用*梯度截断* (当梯度的模大于一定阈值时强制截断) 或*权重衰减* (通过 L1 或 L2 正则化限制参数取值范围), 以维持系统的稳定性.  \
针对梯度消失, 改进方式主要包括: 
+ 一是*改进激活函数*, 使用 ReLU 等导数较大的非饱和激活函数代替 Sigmoid 型函数, 以减小误差项在时间步回传时的衰减; 
+ 二是*优化参数初始化*, 采用正交初始化方法, 使权重矩阵在初始化时满足正交性, 从而在信息前向传播和误差反向传播中具有范数保持性; 
+ 三是*改进模型结构*, 引入类似残差连接的线性依赖机制, 使隐状态更新遵循 $h_t = h_(t-1) + g(x_t, h_(t-1); theta)$, 这种结构能使隐状态间的偏导数接近单位矩阵, 从而有效缓解梯度消失. 

4. 简述记忆网络的典型结构. 

记忆网络的典型结构由*主网络 (控制器) 、外部记忆单元、读取模块和写入模块*四部分组成. 
- 主网络负责核心信息处理及与外界交互, 并生成用于操作记忆的查询向量. 
- 外部记忆单元将信息组织为一组记忆片段 (向量组), 其组织方式可以是集合、树、栈或队列等, 旨在突破神经网络固有的容量限制. 
- 读取模块根据查询向量, 利用注意力机制进行“软性”的内容寻址并提取相关信息; 
- 写入模块则依据控制器的指令更新存储内容. 这种结构通过将计算与存储分离, 使模型能以较少的参数大幅增加记忆容量. 

5. GRU的全称是什么? 相对于LSTM它有什么改进? 根据下图写出状态更新公式. 

#figure(
  image("assets/practice/gru.png"), 
  caption: [GRU网络的循环单元结构]
)

GRU的全称为门控循环单元 (Gated Recurrent Unit). 相对于LSTM, 其主要改进在于结构更加精简: 它将LSTM中的“细胞状态”与“隐藏状态”合并为统一的隐状态 $h_t$, 并将门控机制简化为重置门和更新门两个门控, 从而在保持缓解梯度消失问题的同时, 有效降低了计算复杂度和参数量. 

根据典型的GRU结构, 其状态更新公式主要由以下步骤组成: 
+ 首先计算重置门 $r_t$ 和更新门 $z_t$ 的活性值, 公式分别为 $ r_t = sigma(W_r x_t + U_r h_(t-1) + b_r) $  $ z_t = sigma(W_z x_t + U_z h_(t-1) + b_z) $
+ 随后利用重置门控制上一个时刻状态的贡献程度, 计算候选隐状态 $ tilde(h)_t = tanh(W_h x_t + U_h (r_t dot.o h_(t-1)) + b_h) $
+ 最后通过更新门对历史状态和候选状态进行线性插值, 得到当前时刻的最终隐状态 $ h_t = z_t dot.o h_(t-1) + (1 - z_t) dot.o tilde(h)_t $

6. 什么是尺度不变性? 数据预处理有什么意义? 有哪些方法? 

尺度不变性是指*一个机器学习算法在缩放全部或部分特征后, 其学习和预测过程不受影响的特性*.  \
数据预处理的意义主要在于*提升神经网络的训练效率与模型稳定性*. 如果输入特征的尺度差异过大, 会增加参数初始化的难度, 并导致损失函数的等高线呈不均匀的椭球状, 使得梯度下降时的搜索方向偏离最优路径, 减慢收敛速度. 通过预处理使特征处于相同尺度, 可以改善优化地形, 使梯度方向更接近最优搜索方向, 从而大幅*提高优化效率*. 此外, 对于最近邻等尺度敏感模型, *预处理能防止尺度大的特征在距离计算中占据主导地位*.  \
常用的数据预处理方法包括: 
+ *最小最大值归一化*: 通过线性缩放将特征的取值范围归一到 [0,1] 或 [−1,1] 之间. 
+ *标准化 (Z值归一化) *: 将每一维特征都调整为均值为 0、方差为 1 的标准分布. 
+ *白化*: 通过主成分分析 (PCA) 等手段消除特征之间的相关性, 并使特征具有相同的方差, 从而降低数据冗余. 

7.  (6分) 什么是无监督学习, 包括哪几类? 并简要说明. 

无监督学习 (Unsupervised Learning) 是指*直接从原始数据中学习并发现其中隐藏的有价值信息*, 如有效的特征、类别、结构或概率分布等, 其学习过程不借助人工标注的标签或反馈信息. 典型的无监督学习主要包括以下三类: 
+ *无监督特征学习*: 旨在从无标签的训练数据中自动学习并挖掘有效的特征或表示, 常用于数据降维、可视化或作为监督学习前期的数据预处理, 代表方法有主成分分析 (PCA) 和自编码器 (AE) 等. 
+ *概率密度估计*: 根据一组训练样本来估计样本空间的概率密度函数. 它分为假设数据服从某种已知分布 (如高斯分布) 的参数密度估计, 以及不假设具体分布形式、直接利用样本估计密度的非参数密度估计 (如核密度估计). 
+ *聚类*: 根据特定的准则 (如组内样本相似性高于组间相似性) 将一组样本划分为不同的簇或组, 常见的算法包括 K-Means 算法和谱聚类等. 

8. 什么是终身学习的概念, 跟归纳迁移学习多任务学习的区别? 

*终身学习 (亦称持续学习) 是指机器学习系统能够仿效人类的持续学习能力, 通过不断累积历史任务中学到的经验和知识来辅助新任务的学习, 并确保这些知识持续累积且不被遗忘. *其学习过程中的核心挑战是避免“灾难性遗忘”, 即在学习新任务的过程中, 防止对历史任务至关重要的参数信息被覆盖或破坏. 

终身学习与归纳迁移学习的主要区别在于目标侧重点不同: *归纳迁移学习旨在利用源领域的知识来优化特定目标任务的性能, 其过程通常是单向的, 并不强调知识的长期累积. *相比之下, 终身学习将知识的持续沉淀与在未来任务中的复用视为核心目标. 

终身学习与多任务学习的区别则主要体现在学习的时序性与数据可见性上: *多任务学习是在已知所有相关任务的前提下, 利用所有任务的数据进行并行的联合训练, 以实现任务间的表示共享. *而终身学习则是按照任务出现的先后顺序, 持续地、逐个地进行学习, 并不要求在学习当前任务时能够同时获取所有历史任务的数据. 

9. 请简述神经网络发展的五个主要阶段及其核心标志. 

神经网络的发展历程可分为以下五个阶段:  \
第一阶段为*模型提出期* (1943年-1969年), 由McCulloch和Pitts提出MP模型开启序幕, 随后Rosenblatt提出的感知器模型及其学习算法实现了模拟人类感知能力的初步突破.  \
第二阶段为*冰河期* (1969年-1983年), 因感知器无法处理“异或”回路问题且当时计算机算力不足, 研究进入长达十余年的停滞状态.  \
第三阶段为*反向传播算法引起的复兴期* (1983年-1995年), 反向传播算法 (BP算法) 的流行解决了多层神经网络的学习问题, 同时Hopfield网络和卷积神经网络 (LeNet-5) 在此时期取得了显著成功.  \
第四阶段为*流行度降低期* (1995年-2006年), 支持向量机 (SVM) 等统计学习理论兴起, 神经网络因优化困难、理论基础不清晰及解释性差等缺点再次陷入低潮.  \
第五阶段为*深度学习崛起期* (2006年至今), Hinton提出通过逐层预训练解决深层网络训练难题, 随后伴随大规模并行计算 (GPU) 的普及和海量数据的支持, 深度学习在语音识别和图像分类等任务中取得巨大成功, 标志着神经网络迎来第三次高潮. 

10. 简述批量归一化和层归一化的区别. 

批量归一化 (BN) 与层归一化 (LN) 的主要区别在于*计算归一化统计量的维度不同*. BN 是在小批量 (Batch) 维度上计算均值和方差, 针对单个神经元跨样本进行归一化; 而 LN 是在单个样本的所有特征维度上计算统计量, 针对同层的所有神经元进行归一化. 

从依赖性来看, *BN 的效果强依赖于批量大小, 在小批量场景或动态网络 (如 RNN) 中表现较差; 而 LN 的均值和方差仅取决于当前单个样本, 独立于批量大小, 因此在处理变长序列数据时具有更好的稳定性. *在应用场景上, BN 通常适用于卷积神经网络 (CNN) 及计算机视觉任务, 而 LN 则更适合于循环神经网络 (RNN) 及自然语言处理任务. 

11. 简述神经网络优化算法的主要类别及其核心思路. 

神经网络优化算法主要通过*调整学习率和修正梯度估计*两个方向来提升训练的稳定性和收敛速度.  \
学习率调整类方法旨在通过动态设置步长来平衡搜索效率, 包括*基础的学习率衰减策略 (如余弦衰减、分段常数衰减) 、学习率预热, 以及针对每个参数自适应调节步长的 AdaGrad、RMSprop 和 AdaDelta 等算法*.  \
梯度估计修正类方法则通过引入历史梯度信息来平滑参数更新轨迹, 有效应对随机梯度中的噪声, 代表性方法有*动量法、Nesterov 加速梯度以及结合了动量与自适应学习率优点的 Adam 算法*.  \
此外, *梯度截断*也是一种重要的启发式手段, 通过限制梯度模值来有效缓解训练中的梯度爆炸问题. 

12. 请简述神经网络参数初始化的意义, 并说明为何不能将权重全部初始化为0, 以及常用的初始化方法有哪些. 

参数初始化的意义在于*直接影响神经网络的优化效率与泛化能力*. 由于神经网络的参数学习是一个高维非凸优化问题, 合适的初始值能帮助网络收敛到泛化能力更高的局部最优解, 并有效缓解深层网络中的梯度消失或爆炸问题. 神经网络通常不能将权重参数全部初始化为 0, 因为这会导致“对称权重现象”, 使得第一遍前向计算时隐藏层所有神经元的激活值完全相同, 反向传播时权重的更新也完全一致, *导致神经元失去区分性*.  \
常用的参数初始化方法主要分为三类: 
+ 一是*预训练初始化*, 即利用在大规模数据上训练好的模型参数作为目标任务的初始值进行精调; 
+ 二是*随机初始化*, 包括基于固定方差的采样、旨在保持每层输入输出方差一致的方差缩放初始化 (如适用于 Tanh 函数的 Xavier 初始化和适用于 ReLU 函数的 He 初始化), 以及常用于循环神经网络以保持范数不变的正交初始化; 
+ 三是*固定值初始化*, 即根据经验对偏置等特定参数赋予常数值, 如将 LSTM 遗忘门的偏置设为较大的正值以缓解梯度消失. 

13. 请简述图灵机与神经图灵机 (NTM) 的关系, 并说明神经图灵机的核心组成部分及其寻址机制. 

图灵机是一种用于模拟任何可计算问题的抽象数学模型, 由无限长纸带、读写头、状态寄存器和一套控制规则组成. *神经图灵机 (NTM) 则是将神经网络的模式识别能力与传统计算机的符号处理能力相结合的增强模型. * \
神经图灵机的核心结构由*控制器、读写头和外部存储器*三部分构成. 控制器通常采用循环神经网络 (如 LSTM) 来处理输入并生成控制信号; 读写头在控制器的指挥下对内存进行操作; 外部存储器则是一个大的矩阵, 用于存储历史信息.  \
在寻址机制上, 神经图灵机采用了混合寻址方式: 一是*基于内容的寻址*, 通过计算查询向量与记忆单元中存储向量的相似度来提取信息; 二是*基于位置的寻址*, 通过循环平移实现对内存地址的偏移或随机访问. 为了实现端到端的模型训练, 其读写操作被设计为“软性”的可微操作, 这使得模型能够学会简单的程序逻辑, 如序列复制和排序等任务. 

14. 请简述自训练 (Self-training) 与协同训练 (Co-training) 的基本思想, 并说明两者的主要联系与区别. 

自训练是一种典型的半监督学习算法, 其基本思想是利用标注数据训练模型, 并对无标注样本进行预测, 随后将预测置信度较高的样本及其伪标签加入训练集, 通过不断重复此过程来提升模型性能. 协同训练则是自训练的一种改进方法, 它要求数据具有两个相对独立的“视角”, 通过在不同视角上分别训练模型, 让两个模型互相为对方提供高置信度的伪标签样本来共同促进学习.  \
两者的主要联系在于*均旨在利用海量无标注数据来弥补标注数据的不足, 且在不同视角完全一样时, 协同训练将退化为自训练算法*. 两者的主要区别在于*对数据特征的要求不同*: 自训练通常只涉及单一模型在统一特征集上的迭代更新, 其最大的风险在于无法保证伪标签的准确性; 而协同训练则强调视角的“充足性”与“条件独立性”, 通过不同视角间的信息互补来降低错误传播的概率, 提高学习的稳定性. 

== 计算题

1. 计算下列网络的输出
- *输入* $X$: $3 times 3 times 2$ (通道 $X_1, X_2$)
- *卷积核* $W$: $2 times 2 times 2$ (权重 $W_1, W_2$)
- *参数*: 步长 $S=1$, 填充 $P=0$, 偏置 $b=0.5$
- *流程*: 卷积 $arrow.r$ ReLU $arrow.r$ $2 times 2$ 最大池化

#grid(
  columns: (1fr, 1fr),
  inset: 5pt,
  align: center,
  [*输入通道 $X$*],
  [*卷积核权重 $W$*], 
  $ X_1 = mat(1, 0, 1; 2, 1, 0; 0, 0, 1) $, 
  $ W_1 = mat(1, -1; 0, 1) $, 
  $ X_2 = mat(0, 1, 2; 1, 0, 1; 2, 1, 0) $,
  $ W_2 = mat(0, 1; -1, 0) $

)

卷积输出尺寸为 $2 times 2$. 计算公式为 $Z = (X_1 * W_1) + (X_2 * W_2) + b$. 

- $Z_{1,1} = (1+0+0+1) + (0+1-1+0) + 0.5 = 2.5$
- $Z_{1,2} = (0-1+0+0) + (0+2+0+0) + 0.5 = 1.5$
- $Z_{2,1} = (2-1+0+0) + (0+0-2+0) + 0.5 = -0.5$
- $Z_{2,2} = (1+0+0+1) + (0+1-1+0) + 0.5 = 2.5$

得卷积结果: 
$ Z = mat(2.5, 1.5; -0.5, 2.5) $

应用 $f(x) = max(0, x)$: 
$ A = sigma(Z) = mat(2.5, 1.5; 0, 2.5) $

对 $2 times 2$ 矩阵执行全窗口最大池化: 
$ "Output" = max(2.5, 1.5, 0, 2.5) = bold(2.5) $

*最终结果: 2.5*

2. 给定初值: $a=2, b=3, c=4$, 根据计算图, 计算$(partial f_2) / (partial a), (partial f_2) / (partial b), (partial f_2) / (partial c)$

#figure(
  image("assets/practice/compute-graph.svg", width: 50%), 
  caption: [计算图]
)

给定初值: $a=2, b=3, c=4$. 

- $f_1 = a + b = 2 + 3 = 5$
- $f_2 = c dot f_1 = 4 dot 5 = 20$

根据链式法则, 我们从输出端 $f_2$ 向输入端推导. 

*对 $c$ 的偏导: *
  $ (partial f_2) / (partial c) = f_1 = bold(5) $

*对 $f_1$ 的中间偏导: *
  $ (partial f_2) / (partial f_1) = c = 4 $

*对 $a$ 的偏导: *
  $ (partial f_2) / (partial a) = (partial f_2) / (partial f_1) dot (partial f_1) / (partial a) = 4 dot 1 = bold(4) $

*对 $b$ 的偏导: *
  $ (partial f_2) / (partial b) = (partial f_2) / (partial f_1) dot (partial f_1) / (partial b) = 4 dot 1 = bold(4) $

$ "grad" = [ (partial f_2)/(partial a), (partial f_2)/(partial b), (partial f_2)/(partial c) ] = [4, 4, 5] $

3. 对于一个二维卷积, 输入为$3 times 3$, 卷积核大小为$2 times 2$, 将卷积重写成仿射变换的形式. 

将二维卷积重写为仿射变换 (Affine Transformation) 形式, 本质上是通过构造一个稀疏的卷积矩阵 $C$, 将卷积运算转化为矩阵与向量的乘法 $bold(z) = C bold(x) + bold(b)$. 

首先将输入 $3 times 3$ 的矩阵展平为向量 $ bold(x) = (x_11, x_12, x_13, x_21, x_22, x_23, x_31, x_32, x_33)^T $输出展平为向量 $ bold(z) = (z_11, z_12, z_21, z_22)^T $设卷积核为 $ W = mat(w_11, w_12; w_21, w_22) $
在互相关运算下, 矩阵 $C$ (尺寸 $4 times 9$) 的构造如下: 

$ bold(z) =  vec(z_11, z_12, z_21, z_22) = mat(
  w_11, w_12, 0, w_21, w_22, 0, 0, 0, 0;
  0, w_11, w_12, 0, w_21, w_22, 0, 0, 0;
  0, 0, 0, w_11, w_12, 0, w_21, w_22, 0;
  0, 0, 0, 0, w_11, w_12, 0, w_21, w_22
) vec(x_11, x_12, x_13, x_21, x_22, x_23, x_31, x_32, x_33) + bold(b) $

该矩阵 $C$ 具有明显的*稀疏性*, 其非零元素仅由卷积核元素组成; 每一行仅 4 个非零元素体现了*局部连接*; 不同行间重复使用相同权重则体现了*权重共享*. 通过此形式, 卷积层可视为一种特殊的、连接受限的全连接层. 

= 绪论

== 核心考点速记

#table(
  columns: (1fr, 3fr),
  inset: 5pt,
  align: (x, y) => if (x == 1 and y != 0) {left} else {horizon},
  [*考点模块*], [*核心内容与关键词*],
  
  [*AI基础与历史*],
  [- *图灵测试*: 判断机器是否智能的标准. 
  - *三大流派*: 
    1. *符号主义 (Symbolism)*: 逻辑演绎、显式规则, 可解释性强. 
    2. *连接主义 (Connectionism)*: 神经网络、仿生、分布式并行处理, 深度学习属于此流派. 
    3. *行为主义*: 进化与环境交互 (如强化学习). ],

  [*机器学习与深度学习*],
  [- *浅层学习 vs 深度学习*: 浅层学习依赖人工*特征工程*；深度学习通过多层结构自动进行*特征学习* (表示学习). 
  - *贡献度分配问题 (CAP)*: 深度学习的核心难点, 即如何确定系统中每个组件对最终结果的贡献. ],

  [*表示学习 (重难点)*],
  [- *语义鸿沟*: 底层特征 (如像素) 与高层语义之间的差异. 
  - *局部表示*: 如 One-hot 向量. 解释性好但维数高 (稀疏)、无法表示相似度. 
  - *分布式表示*: 如 词嵌入. 维数低 (稠密)、表示能力强、*可计算相似度*. ],

  [*神经网络发展史*],
  [- *五大阶段*: 模型提出 (MP模型, 感知器) $arrow.r$ 冰河期 (Minsky 指出 XOR 问题) $arrow.r$ 复兴 (反向传播 BP 算法) $arrow.r$ 低潮 $arrow.r$ 崛起 (深度信念网络). 
  - *赫布规则*: 两个神经元同时兴奋则连接增强. ]
)

== 考题预测

=== 选择题

1. *(单选/多选)* 关于人工智能流派, 下列说法正确的是：
  - A. 深度学习属于符号主义流派
  - B. 符号主义主要通过逻辑运算操作符号, 具有较好的可解释性
  - C. 连接主义认为认知过程是神经元网络中的信息处理过程
  - D. 专家系统是连接主义的典型代表

2. *(单选)* 1969年, Marvin Minsky 出版《感知器》一书指出当时的神经网络 (感知器) 存在两个关键缺陷, 导致了神经网络研究进入“冰河期”. 这两个缺陷是：
  - A. 无法解决异或 (XOR) 问题；计算机算力不足
  - B. 梯度消失问题；过拟合问题
  - C. 缺乏大量训练数据；缺乏有效的优化算法
  - D. 局部极小值问题；参数初始化困难

3. *(单选)* 在表示学习中, 关于“局部表示” (Local Representation) 和“分布式表示” (Distributed Representation) 的对比, 下列说法错误的是：
  - A. One-hot 向量是典型的局部表示
  - B. 分布式表示通常对应低维稠密向量
  - C. 局部表示很容易计算两个概念之间的语义相似度
  - D. 分布式表示的表示能力通常强于局部表示

4. *(多选)* 深度学习区别于传统浅层机器学习的主要特征包括：
  - A. 能够自动学习特征, 避免繁琐的人工特征工程
  - B. 通常采用“端到端”的学习方式
  - C. 模型结构通常具有多层非线性转换
  - D. 只能处理图像数据, 不能处理文本数据

=== 简答题

1. 简述“语义鸿沟” (Semantic Gap) 的概念, 并说明深度学习如何解决这一问题. 
2. 什么是“贡献度分配问题” (Credit Assignment Problem, CAP)？为什么说它是深度学习的关键？
3. *(高频考点)* 简述神经网络发展的五个主要阶段及每个阶段的标志性事件. 

== 答案与解析

=== 选择题答案

#table(
  columns: (1fr, 1fr, 1fr, 1fr),
  inset: 10pt,
  align: center,
  [*1*], [*2*], [*3*], [*4*],
  [BC], [A], [C], [ABC]
)

=== 答案解析

*1. 解析：*
A错误, 深度学习属于连接主义；B正确, 符号主义基于逻辑运算和显式规则；C正确, 这是连接主义的核心观点；D错误, 专家系统是符号主义 (知识期) 的典型代表. 

*2. 解析：*
A正确. 1969年 Minsky 指出感知器无法处理“异或”回路问题, 且当时计算机无法支持大型网络计算, 导致研究进入冰河期. 

*3. 解析：*
C错误. 局部表示 (如 One-hot) 中不同向量正交, 相似度为0, 无法体现语义相似性. 分布式表示可以很容易计算相似度. 

*4. 解析：*
A、B、C正确. 深度学习的核心是自动学习特征 (表示学习), 通常是端到端的, 且包含多层非线性转换. D错误, 深度学习可处理文本、语音等多种数据. 

=== 简答题参考答案

*1. 语义鸿沟 (Semantic Gap)*
- *概念*: 语义鸿沟是指输入数据的底层特征 (如图像的像素值) 与高层语义信息 (如“这是一辆车”) 之间的不一致性和差异性. 
- *解决*: 深度学习通过构建具有一定“深度”的多层神经网络, 将原始数据经过多步非线性特征转换, 从底层特征逐步抽象到中层、高层特征, 从而自动学习到能反映数据高层语义的表示. 

*2. 贡献度分配问题 (CAP)*
- *定义*: 指在一个复杂的系统中 (如多层神经网络), 当我们得到最终的输出结果 (如分类正确或错误) 时, 并不清楚系统中每个内部组件 (或参数) 对这个结果的贡献或影响是多少. 
- *关键性*: 深度学习模型通常包含大量参数和多层结构, 只有解决了CAP问题, 才能知道如何更新每个组件的参数以优化模型. 神经网络利用误差反向传播算法有效地解决了这一问题. 

*3. 神经网络发展的五个阶段*
- *模型提出 (1943-1969)*: McCulloch & Pitts 提出 MP 模型；Rosenblatt 提出感知器. 
- *冰河期 (1969-1983)*: Minsky 出版《感知器》指出无法解决 XOR 问题, 研究陷入停滞. 
- *复兴 (1983-1995)*: Hinton 等人完善反向传播 (BP) 算法；LeCun 提出卷积神经网络. 
- *低潮 (1995-2006)*: 支持向量机 (SVM) 等统计学习方法兴起, 神经网络因优化困难和解释性差受冷落. 
- *崛起 (2006-至今)*: Hinton 提出深度信念网络 (预训练+精调)；GPU 算力提升与大数据爆发. 

= 前馈神经网络

== 考点分析

本章作为深度学习的基石, 重点考察以下核心内容：

+ *神经元与激活函数 (High Frequency)*
  - *MP神经元模型*：理解净输入 $z$ 与活性值 $a$ 的关系. 
  - *激活函数的性质*：
    - *Sigmoid型*：$sigma(x)$ 与 $tanh(x)$ 的形状、值域及导数特性 (饱和区导致梯度消失). 
    - *ReLU及其变体*：$"ReLU"(x) = max(0, x)$ 的优势 (高效、稀疏性、缓解梯度消失) 及“死亡ReLU”问题. 
  - *通用近似定理*：理解前馈神经网络逼近连续函数的能力. 

+ *前馈神经网络结构*
  - *参数计算*：能够准确计算全连接层的权重矩阵 $W$ 和偏置向量 $b$ 的维度及参数总数. 
  - *全连接层公式*：$z^((l)) = W^((l)) a^((l-1)) + b^((l))$. 

+ *反向传播算法 (Backpropagation) - 核心难点*
  - *链式法则*：BP算法的数学基础. 
  - *误差项传递*：掌握 $delta^((l))$ 的定义及递推公式 $delta^((l)) = f'_l (z^((l))) dot ((W^((l+1)))^T delta^((l+1)))$. 
  - *梯度计算*：$partial cal(L) / partial W^((l)) = delta^((l)) (a^((l-1)))^T$. 

+ *优化与正则化*
  - *梯度消失*：成因 (Sigmoid导数特性、深层网络连乘) 及解决方案. 
  - *参数初始化*：全0初始化的危害 (对称权重现象). 

== 考题预测

=== 选择题

1. (基础概念) 下列关于激活函数的说法, 错误的是：
  - A. Sigmoid 函数的输出范围是 $(0, 1)$, 可解释为概率. 
  - B. Tanh 函数是零中心化的 (Zero-Centered), 收敛速度通常快于 Sigmoid. 
  - C. ReLU 函数在 $x > 0$ 时导数为 1, 可以完全解决梯度消失问题. 
  - D. Softplus 函数是 ReLU 的平滑版本, 但计算量相对较大. 

2. (参数计算) 假设一个前馈神经网络, 输入层有 $D$ 个神经元, 隐藏层有 $M$ 个神经元, 输出层有 $K$ 个神经元. 若包含偏置项, 该网络第一层 (输入到隐藏) 和第二层 (隐藏到输出) 的可学习参数总数为：
  - A. $D times M + M times K$
  - B. $(D + 1) times M + (M + 1) times K$
  - C. $(D times M + 1) + (M times K + 1)$
  - D. $D times (M + 1) + M times (K + 1)$

3. (反向传播) 在反向传播算法中, 若损失函数为 $cal(L)$, 第 $l$ 层的误差项为 $delta^((l))$, 则第 $l$ 层权重矩阵 $W^((l))$ 的梯度 $partial cal(L) / partial W^((l))$ 等于：
  - A. $delta^((l)) (a^((l-1)))^T$
  - B. $(a^((l-1)))^T delta^((l))$
  - C. $W^((l)) delta^((l))$
  - D. $delta^((l)) dot f'(z^((l)))$

4. (优化问题) 下列哪项不是导致梯度消失问题的主要原因？
  - A. 网络层数过深
  - B. 使用 Sigmoid 激活函数
  - C. 权值初始化过小
  - D. 使用 ReLU 激活函数

=== 简答题

1. *激活函数性质*：请简述激活函数在神经网络中的作用. 如果将多层前馈神经网络中的所有激活函数都替换为线性函数 $f(x) = c x$, 网络会有什么变化？

2. *梯度消失*：请结合 Sigmoid 函数的导数特性, 解释梯度消失问题产生的原因, 并列举一种解决方案. 

3. *参数初始化*：为什么在训练神经网络时, 不能将所有权重参数 $W$ 初始化为 0？

=== 计算题

1. *计算图与导数*
  给定计算图对应的函数 $f(x, w, b) = 1 / (exp(-(w x + b)) + 1)$. 
  设输入 $x = 1$, 参数初始值 $w = 0, b = 0$. 
  (1) 画出该函数的计算图 (将计算分解为基本算子). 
  (2) 利用反向传播 (链式法则) 计算 $f$ 对 $w$ 的偏导数 $partial f / partial w$. 

2. *反向传播推导*
  设第 $l$ 层的误差项为 $delta^((l))$, 第 $l+1$ 层的误差项为 $delta^((l+1))$. 
  已知 $z^((l+1)) = W^((l+1)) a^((l)) + b^((l+1))$ 且 $a^((l)) = f_l (z^((l)))$. 
  请证明递推公式：
  $ delta^((l)) = f'_l (z^((l))) dot ((W^((l+1)))^T delta^((l+1))) $
  其中 $dot$ 表示逐元素相乘 (Hadamard积). 

== 答案与解析

=== 选择题答案

#align(center)[
  #table(
    columns: (auto, auto, auto, auto),
    inset: 10pt,
    align: center,
    [*1*], [*2*], [*3*], [*4*],
    [C], [B], [A], [D]
  )
]

=== 解析

==== 选择题解析

1. *解析*：C. ReLU 虽然缓解了梯度消失, 但并未完全解决 (如在深层网络中连乘导致数值问题, 或 $x < 0$ 时导数为 0), 且存在“死亡 ReLU”问题, 即神经元可能永久不被激活. 
2. *解析*：B. 
  - 第一层权重参数：$D times M$, 偏置参数：$M$. 合计：$(D+1)M$. 
  - 第二层权重参数：$M times K$, 偏置参数：$K$. 合计：$(M+1)K$. 
  - 总计：$(D + 1) times M + (M + 1) times K$. 
3. *解析*：A. 根据教材公式 (4.68), 权重梯度等于本层误差项 $delta^((l))$ 与上一层激活值向量 $a^((l-1))$ 的外积. 
4. *解析*：D. ReLU 在正区间的导数为 1, 能够有效保持梯度不衰减, 它是缓解梯度消失的常用手段, 而非成因. 

==== 简答题参考答案

1. *激活函数的作用与线性化后果*：
  - *作用*：激活函数引入非线性因素, 使神经网络具备逼近任意复杂非线性函数的能力 (通用近似定理). 
  - *后果*：若使用线性函数, 无论网络层数多少, 输出均为输入的线性组合. 
  - *结论*：多层网络将退化为单层线性模型 (如感知器), 失去处理非线性问题 (如XOR) 的能力. 

2. *梯度消失成因与方案*：
  - *成因*：Sigmoid 导数 $sigma'(x) = sigma(x)(1 - sigma(x))$ 最大值为 0.25. 反向传播时, 误差项通过链式法则向前传递, 涉及多个小于 1 的导数连乘. 随层数增加, 梯度值呈指数级衰减, 导致靠近输入层的参数无法更新. 
  - *解决方案*：
    - 使用 ReLU 激活函数 ($x>0$ 时导数为 1) ；
    - 使用 Batch Normalization (批量归一化) ；
    - 使用 ResNet 残差连接. 

3. *参数初始化不为0的原因*：
  - *前向传播*：若 $W=0$, 同层所有神经元输入相同, 激活输出完全相同. 
  - *反向传播*：输出相同导致梯度更新值完全相同. 
  - *后果*：引发“对称权重”现象, 同层神经元功能同质化, 网络退化为单神经元网络, 无法学习复杂特征. 

==== 计算题参考步骤

1. *计算图与导数*：
  *前向计算步骤*：
  $
  h_1 &= w x + b = 0 times 1 + 0 = 0 \
  h_2 &= exp(-h_1) = exp(0) = 1 \
  h_3 &= h_2 + 1 = 2 \
  f &= 1 / h_3 = 0.5
  $
  *反向计算步骤*：
  $
  partial f / partial h_3 &= -1 / h_3^2 = -0.25 \
  partial h_3 / partial h_2 &= 1 \
    arrow.r partial f / partial h_2 &= -0.25 \
  partial h_2 / partial h_1 &= -exp(-h_1) = -1 \
    arrow.r partial f / partial h_1 &= (-0.25) times (-1) = 0.25 \
  partial h_1 / partial w &= x = 1 \
    arrow.r partial f / partial w &= 0.25 times 1 = 0.25
  $

2. *反向传播递推公式证明*：
  根据链式法则展开误差项定义 $delta^((l)) = (partial cal(L)) / (partial z^((l)))$：
  $
  delta^((l)) = (partial cal(L)) / (partial z^((l+1))) times (partial z^((l+1))) / (partial a^((l))) times (partial a^((l))) / (partial z^((l)))
  $
  代入各部分导数：
  - 第一项：下一层误差项 $(partial cal(L)) / (partial z^((l+1))) = delta^((l+1))$
  - 第二项：$z^((l+1)) = W^((l+1)) a^((l)) + b^((l+1))$, 对 $a^((l))$ 求导得 $W^((l+1))$. 由于是反向传递, 矩阵需转置, 即 $(W^((l+1)))^T$. 
  - 第三项：$a^((l)) = f_l (z^((l)))$, 求导得 $f'_l (z^((l)))$. 
  
  合并得到：
  $ delta^((l)) = f'_l (z^((l))) dot ((W^((l+1)))^T delta^((l+1))) $

= 卷积神经网络

== 考点分析

本章前两节主要考察卷积运算的数学机制与卷积神经网络的基础结构特性. 

#table(
  columns: (1fr, 3fr),
  align: (center, left),
  [*考点*], [*核心要点*],
  [*卷积运算*], [
    - *互相关 vs 卷积*：深度学习中的“卷积”通常指互相关 (不翻转), 严格数学定义的卷积需要旋转核180度 . 
    - *输出尺寸公式*：$M' = floor((M - K + 2P)/S) + 1$, 其中 $M$为输入, $K$为核大小, $P$为填充, $S$为步长 . 
    - *卷积类型*：窄卷积($P=0$)、宽卷积($P=K-1$)、等宽卷积($P=(K-1)/2$) [cite: 156-159]. 
  ],
  [*网络特性*], [
    - *三大核心特性*：局部连接、权重共享、汇聚 (Pooling). 
    - *参数共享*：卷积核在整张图像上滑动, 参数固定, 大大减少了参数量 . 
  ],
  [*参数计算*], [
    - *卷积层参数量*：$(U times V times D_"in") times D_"out" + D_"out"$ (偏置) . 
    - *连接数*：输出特征图像素数 $times$ 单个神经元的连接数 . 
  ]
)

== 考题预测

=== 选择题

1. 在卷积神经网络中, 若输入特征图大小为 $100 times 100$, 卷积核大小为 $5 times 5$, 步长 $S=1$, 若要保证输出特征图大小与输入一致 (即等宽卷积), 则零填充 (Padding) $P$ 应设置为：
  - A. 0
  - B. 1
  - C. 2
  - D. 3

2. 假设某卷积层的输入深度 (通道数) 为 3, 输出深度为 10, 卷积核大小为 $3 times 3$. 若包含偏置项, 则该层可学习的参数数量为：
  - A. 90
  - B. 100
  - C. 270
  - D. 280

3. 关于卷积神经网络中的“权重共享”特性, 下列说法正确的是：
  - A. 同一卷积层中, 不同通道的卷积核权重是共享的
  - B. 同一卷积层中, 同一个卷积核在输入特征图不同位置滑动时, 其权重是共享的
  - C. 不同卷积层之间的权重是共享的
  - D. 权重共享增加了网络的自由度, 容易导致过拟合

4. (多选) 下列关于汇聚层 (Pooling Layer) 的描述, 正确的是：
  - A. 汇聚层可以显著减少特征图的尺寸, 降低计算量
  - B. 最大汇聚 (Max Pooling) 选取区域内的最大值, 能较好地保留纹理特征
  - C. 平均汇聚 (Mean Pooling) 选取区域内的平均值, 能较好地保留背景信息
  - D. 汇聚层通常包含大量的可学习参数

#v(1em)
*选择题参考答案*
#table(
  columns: (1fr, 1fr, 1fr, 1fr),
  align: center,
  [1], [2], [3], [4],
  [C], [D], [B], [A, B, C]
)

*选择题解析*
1. *解析*：根据输出尺寸公式 $(M - K + 2P)/S + 1 = M$, 代入 $S=1, K=5$, 解得 $2P = K - 1 = 4$, 故 $P=2$ . 
2. *解析*：参数量公式为 $(K times K times D_"in") times D_"out" + D_"out"$. 计算为 $(3 times 3 times 3) times 10 + 10 = 27 times 10 + 10 = 280$ . 
3. *解析*：权重共享是指同一个卷积核在处理输入特征图的不同位置时使用相同的参数 . 不同通道对应卷积核的不同切片, 参数不共享；不同层之间参数也不共享. 
4. *解析*：汇聚层通过下采样减小尺寸 . 最大汇聚提取局部最显著特征 (如纹理、边缘), 平均汇聚提取背景或整体特征 . 标准汇聚层通常没有可学习参数 (不像卷积层有权重). 

=== 简答与计算题

1. *简答题*：请简述卷积神经网络中“局部连接”与“全连接”的区别, 并说明局部连接的优势. 

*解析*：
- *区别*：
  - *全连接*：第 $l$ 层的每个神经元与第 $l-1$ 层的所有神经元相连, 参数量巨大 . 
  - *局部连接*：第 $l$ 层的神经元只与第 $l-1$ 层中一个局部窗口 (感受野) 内的神经元相连 . 
- *优势*：
  - 大幅减少了连接数量和权重参数的数量, 降低了模型复杂度, 缓解过拟合 . 
  - 符合图像的空间局部相关性, 即像素之间的联系主要存在于局部区域 . 

2. *计算题*：
给定一个 $5 times 5$ 的输入图像 $X$ 和一个 $3 times 3$ 的卷积核 $W$ (如下所示), 步长 $S=1$, 无零填充 ($P=0$). 请计算卷积 (互相关) 后的输出特征图 $Y$. 
$ X = mat(
  1, 1, 1, 0, 0;
  0, 1, 1, 1, 0;
  0, 0, 1, 1, 1;
  0, 0, 1, 1, 0;
  0, 1, 1, 0, 0
), quad W = mat(
  1, 0, 1;
  0, 1, 0;
  1, 0, 1
) $

*解析*：
- *输出尺寸计算*：$M=5, K=3, S=1, P=0$. 输出边长 $M' = (5-3+0)/1 + 1 = 3$. 输出为 $3 times 3$ 矩阵 . 
- *数值计算* (互相关运算 $Y = W * X$): 
  - $y_(1,1)$ (对应X左上角 $3 times 3$): 
    $1(1)+0(1)+1(1) + 0(0)+1(1)+0(1) + 1(0)+0(0)+1(1) = 1+0+1+0+1+0+0+0+1 = 4$
  - $y_(1,2)$ (窗口右移一格):
    $1(1)+0(1)+1(0) + 0(1)+1(1)+0(1) + 1(0)+0(1)+1(1) = 1+0+0+0+1+0+0+0+1 = 3$
  - $y_(1,3)$: $1(1)+1(0)+1(0) + 1(1)+1(1)+0(0) + 1(1)+1(1)+1(1) = 1+0+0+1+1+0+1+1+1 = 6$
  - $y_(2,1)$: $0(1)+1(1)+1(1) + 0(0)+0(1)+1(0) + 0(0)+1(0)+1(1) = 0+1+1+0+0+0+0+0+1 = 3$
  - $y_(2,2)$ (中心): $1(1)+1(1)+1(1) + 0(0)+1(1)+1(0) + 1(0)+1(0)+1(0) = 1+1+1+0+1+0+0+0+0 = 4$
  - $y_(2,3)$: $1(1)+1(0)+0(1) + 1(0)+1(1)+1(0) + 1(0)+0(0)+0(1) = 1+0+0+0+1+0+0+0+0 = 2$
  - $y_(3,1)$: $0(1)+0(1)+1(1) + 0(0)+0(1)+1(0) + 0(0)+1(0)+1(1) = 0+0+1+0+0+0+0+0+1 = 2$
  - $y_(3,2)$: $0(1)+1(1)+1(1) + 0(0)+1(1)+1(0) + 1(0)+1(0)+0(1) = 0+1+1+0+1+0+0+0+0 = 3$
  - $y_(3,3)$: $1(1)+1(0)+1(1) + 1(0)+1(1)+0(0) + 1(0)+0(0)+0(1) = 1+0+1+0+1+0+0+0+0 = 3$
- *最终结果*：
  $ Y = mat(
    4, 3, 6;
    3, 4, 2;
    2, 3, 3
  ) $

= 循环神经网络

== 核心考点预测

本章在期末考试中通常占据较大比重, 考察形式涵盖选择、简答及计算推导. 

+ *循环神经网络 (RNN) 基础*：
  - 了解RNN与前馈神经网络 (FNN) 的区别 (记忆能力、参数共享). 
  - 掌握简单循环网络的状态更新公式 $h_t = f(U h_(t-1) + W x_t + b)$. 
  - 理解Seq2Seq模式 (同步/异步). 

+ *随时间反向传播算法 (BPTT) *：
  - *重点*：理解BPTT是将RNN按时间展开后的BP算法. 
  - 掌握梯度计算中“按时间累积”的概念. 
  - 能够写出损失函数关于参数 $U$ (状态-状态权重) 的梯度通式. 

+ *长程依赖问题*：
  - 理解梯度消失和梯度爆炸的数学本质 (权重矩阵的连乘). 
  - 掌握解决梯度爆炸的方法 (梯度截断) 和梯度消失的方法 (门控机制、残差连接). 

+ *门控循环神经网络 (LSTM & GRU) *：
  - *LSTM*：掌握三个门 (遗忘门、输入门、输出门) 的功能, 特别是遗忘门的作用；理解记忆单元 $c_t$ 与 隐状态 $h_t$ 的区别. 
  - *GRU*：掌握两个门 (重置门、更新门) 的功能；对比GRU与LSTM的参数量与结构差异. 

== 考题预测

=== 选择题

1. 在循环神经网络 (RNN) 中, 关于随时间反向传播算法 (BPTT), 下列说法错误的是【 】
  - A. BPTT算法主要用于计算RNN中的参数梯度
  - B. 随着序列长度增加, BPTT计算梯度的路径会变长, 容易导致梯度消失或爆炸
  - C. 为了降低计算复杂度, 通常可以使用截断的BPTT (Truncated BPTT) 
  - D. BPTT中, 参数 $U$ 的梯度只取决于当前时刻 $t$ 的误差, 与历史时刻无关

2. 导致简单循环神经网络 (Simple RNN) 难以训练“长程依赖”问题的主要原因是【 】
  - A. 激活函数导数过大
  - B. 随着时间步增加, 梯度在反向传播时经过连乘产生指数级衰减或增长
  - C. 网络参数数量过多导致过拟合
  - D. 损失函数定义不合理

3. 长短期记忆网络 (LSTM) 通过引入门控机制解决了梯度消失问题. 其中, 控制上一时刻的内部状态 $c_(t-1)$ 有多少信息需要保留到当前时刻 $c_t$ 的是【 】
  - A. 输入门 (Input Gate)
  - B. 遗忘门 (Forget Gate)
  - C. 输出门 (Output Gate)
  - D. 重置门 (Reset Gate)

4. 相比于LSTM, 门控循环单元 (GRU) 的结构更为简单. 下列关于GRU的描述正确的是【 】
  - A. GRU 包含三个门：输入门、遗忘门和输出门
  - B. GRU 引入了独立的记忆单元 (Cell State) $c_t$ 和隐状态 $h_t$
  - C. GRU 将遗忘门和输入门合并为一个更新门 (Update Gate)
  - D. GRU 的参数量通常多于同等隐层大小的 LSTM

5. (多选) 针对循环神经网络中的梯度爆炸问题, 有效的解决方案包括【 】
  - A. 梯度截断 (Gradient Clipping)
  - B. 权重衰减 (Weight Decay / L2 正则化)
  - C. 将激活函数更换为 Sigmoid
  - D. 使用 ReLU 激活函数并配合特定的参数初始化

=== 简答题

1. *简述随时间反向传播 (BPTT) 算法的基本思想, 并说明它与标准反向传播 (BP) 算法的区别. *

  *参考答案：*
  - *基本思想*：BPTT 是基于误差反向传播算法训练循环神经网络的方法. 其核心思想是将循环神经网络在时间维度上进行展开, 将其看作一个参数共享的深层前馈神经网络. 
  - *区别*：
    1. *结构展开*：标准 BP 用于层数固定的前馈网络；BPTT 需将网络按时间步 $t$ 展开, 层数等于序列长度. 
    2. *参数共享*：BPTT 中, 展开后的每一层 (每个时间步) 共享同一组权重参数 ($U, W, b$). 
    3. *梯度累加*：计算参数梯度时, BPTT 需要将所有时间步计算得到的梯度进行累加 (或平均), 而不仅仅是当前层的梯度. 

2. *分析循环神经网络中梯度消失产生的原因, 并从数学角度解释为什么LSTM能缓解这一问题. *

  *参考答案：*
  - *梯度消失原因*：在简单RNN中, 反向传播时梯度包含形如 $product_(k=t)^(T) "diag"(f') W$ 的连乘项. 如果权重矩阵的模或激活函数的导数小于1, 随着时间步 $t$ 的增加, 连乘项会趋近于0, 导致长距离的梯度无法传导到初始时刻. 
  - *LSTM的缓解机制*：
    1. LSTM引入了内部状态 $c_t$, 其更新公式近似为 $c_t = f_t dot c_(t-1) + i_t dot tilde(c)_t$. 
    2. 在反向传播求导 $(partial c_t) / (partial c_(t-1))$ 时, 梯度主要受遗忘门 $f_t$ 控制. 
    3. 如果遗忘门 $f_t approx 1$, 梯度可以无损地 (线性地) 在时间维度上传播, 形成“常数误差传送带” (Constant Error Carousel), 从而避免了连乘导致的梯度快速衰减. 

3. *对比LSTM与GRU的区别. *

  *参考答案：*
  - *结构差异*：LSTM 有三个门 (输入、遗忘、输出) 和一个独立的记忆单元 $c_t$；GRU 只有两个门 (更新门、重置门), 直接对隐状态 $h_t$ 进行操作, 无独立记忆单元. 
  - *功能合并*：GRU 将 LSTM 的输入门和遗忘门的功能融合到了更新门中. 
  - *计算效率*：由于门控数量减少, GRU 的参数量比 LSTM 少, 计算与训练速度通常更快, 但表达能力在某些复杂任务上可能略弱于 LSTM. 

=== 计算题

*题目：简单循环神经网络的梯度推导*

考虑一个简单的循环神经网络, 在时刻 $t$ 的状态更新公式为：
$ h_t = f(z_t) = f(U h_(t-1) + W x_t + b) $
其中 $f(dot)$ 为激活函数. 假设 $t$ 时刻的损失函数为 $L_t$. 

1. 写出 $t$ 时刻的净输入 $z_t$ 关于上一时刻状态 $h_(t-1)$ 的直接导数. 
2. 定义误差项 $delta_(t, k) = (partial L_t) / (partial z_k)$ (其中 $k < t$). 请利用链式法则, 推导 $delta_(t, k)$ 与 $delta_(t, k+1)$ 之间的递推关系式. 
3. 说明当时间间隔 $t-k$ 很大时, 上述递推关系如何导致梯度问题. 

*参考解答：*

*1. 净输入关于上一时刻状态的导数：*
由 $z_t = U h_(t-1) + W x_t + b$, 可知：
$ (partial z_t) / (partial h_(t-1)) = U $
注意：若考虑 $h_(t-1) = f(z_(t-1))$, 则 $(partial h_(t-1)) / (partial z_(t-1)) = "diag"(f'(z_(t-1)))$. 

*2. 误差项递推关系推导：*
根据链式法则 (BPTT的核心): 
$ delta_(t, k) = (partial L_t) / (partial z_k) = (partial L_t) / (partial z_(k+1)) dot (partial z_(k+1)) / (partial h_k) dot (partial h_k) / (partial z_k) $

代入已知项：
- $(partial L_t) / (partial z_(k+1)) = delta_(t, k+1)$
- $(partial z_(k+1)) / (partial h_k) = U$
- $(partial h_k) / (partial z_k) = "diag"(f'(z_k))$

因此递推关系为：
$ delta_(t, k) = delta_(t, k+1) dot U dot "diag"(f'(z_k)) $
或者写成转置形式 (取决于向量定义习惯, 通常在反向传播中): 
$ delta_(t, k) = "diag"(f'(z_k)) U^T delta_(t, k+1) $

*3. 梯度问题分析：*
将上述递推公式展开, 从 $t$ 时刻传回到 $k$ 时刻：
$ delta_(t, k) = (product_(tau=k)^(t-1) "diag"(f'(z_tau)) U^T) delta_(t, t) $
当 $t-k$ 很大时, 梯度包含 $U^T$ 的 $t-k$ 次连乘. 
- 若 $||U||$ 的特征值 $< 1$ 且激活函数导数 $< 1$ (如Tanh/Sigmoid), 连乘结果趋向于0, 导致*梯度消失*. 
- 若 $||U||$ 的特征值 $> 1$ (且未被激活函数导数抵消), 连乘结果趋向于无穷, 导致*梯度爆炸*. 

= 网络优化与正则化

== 考点分析

根据教材第7章内容, 本章重点在于如何让深度网络“训练得更好” (优化) 和“泛化得更好” (正则化). 

1.  *高维非凸优化 (Optimization)*
    -   *鞍点 (Saddle Point)*：高维空间中梯度为0的点主要是鞍点, 而非局部最小值. 这是优化的主要障碍. 
    -   *平坦最小值 (Flat Minima)*：相比尖锐最小值, 平坦最小值对应的模型泛化能力更强. 

2.  *优化算法 (Algorithms)*
    -   *动量法 (Momentum)*：利用历史梯度信息 (动量) 加速收敛, 抑制振荡. 
    -   *自适应学习率*：
        -   *RMSprop*：引入衰减率 $rho$, 计算梯度平方的指数加权移动平均, 解决AdaGrad学习率过早衰减问题. 
        -   *Adam*：结合动量法 (一阶矩) 和RMSprop (二阶矩). 

3.  *参数初始化 (Initialization)*
    -   *对称性破坏*：不能全0初始化. 
    -   *Xavier初始化*：保持方差一致, 适用于 Sigmoid/Tanh. 
    -   *He初始化 (Kaiming)*：考虑ReLU的一半抑制特性, 方差为 $2/N_"in"$. 

4.  *逐层归一化 (Normalization) [核心考点]*
    -   *Batch Normalization (BN)*：
        -   训练时计算当前Batch的均值方差, 测试时使用全局移动平均. 
        -   引入 $gamma$ (缩放) 和 $beta$ (平移) 以恢复表达能力. 
        -   不适用于RNN (动态序列长度) 和 Batch Size过小的情况. 
    -   *Layer Normalization (LN)*：
        -   对单个样本的所有特征进行归一化. 
        -   独立于Batch Size, 适用于RNN. 

5.  *正则化 (Regularization)*
    -   *Dropout*：训练时随机丢弃, 测试时缩放输出 (或训练时倒置缩放). 
    -   *权重衰减*：在SGD中等价于L2正则化. 
    -   *标签平滑*：将硬标签 $y=[0,1,0]$ 变成软标签 $y=[epsilon, 1-2epsilon, epsilon]$, 防止过拟合. 

== 考题预测

=== 选择题

1. 在深度神经网络的损失函数曲面上, 梯度为0的点最常见的是哪种类型, 这往往是基于梯度的优化算法面临的主要困难？
  - A. 全局极小值 (Global Minima)
  - B. 局部极小值 (Local Minima)
  - C. 鞍点 (Saddle Point)
  - D. 尖锐极大值 (Sharp Maxima)

2. 关于批量归一化 (Batch Normalization, BN), 下列说法*错误*的是？
  - A. BN 引入了可学习参数 $gamma$ 和 $beta$ 来进行仿射变换. 
  - B. 在推理 (Inference/Testing) 阶段, BN 使用当前输入 Batch 的统计量进行归一化. 
  - C. BN 通常放置在线性变换之后, 非线性激活函数之前. 
  - D. BN 可以使优化地形更加平滑, 从而允许使用更大的学习率. 

3. 在使用 ReLU 作为激活函数的深层网络中, 为了防止梯度消失或爆炸, 最合适的参数初始化方法是？
  - A. 将所有权重初始化为 0
  - B. 标准高斯分布初始化 $cal(N)(0, 1)$
  - C. Xavier 初始化
  - D. He (Kaiming) 初始化

4. 关于 Dropout (丢弃法), 假设训练时的保留概率为 $p$ (即神经元以概率 $p$ 存活), 若采用标准的 Dropout 实现 (训练时输出不缩放), 在测试阶段应该如何处理神经元的输出？
  - A. 输出值乘以 $p$
  - B. 输出值除以 $p$
  - C. 输出值乘以 $(1-p)$
  - D. 不做任何处理

5. RMSprop 算法相对于 AdaGrad 算法的主要改进在于？
  - A. 引入了动量项来加速收敛. 
  - B. 使用梯度平方的指数加权移动平均代替全部历史梯度的平方和, 防止学习率过早衰减. 
  - C. 对梯度进行了截断, 防止梯度爆炸. 
  - D. 引入了偏差修正项. 

#align(center)[
  *选择题答案速查*
  #table(
    columns: (auto, auto, auto, auto, auto),
    align: center + horizon,
    [*1*], [*2*], [*3*], [*4*], [*5*],
    [C], [B], [D], [A], [B]
  )
]

*选择题解析*

1.  *解析：C*. 在高维非凸优化问题中, 大部分驻点 (梯度为0) 是鞍点. 鞍点在一个方向是极大值, 另一个方向是极小值, 导致Hessian矩阵非正定, 容易让优化算法犹豫不决. 
2.  *解析：B*. B选项错误. 在训练阶段, BN使用当前Batch的均值和方差；但在推理 (测试) 阶段, 样本可能是一个一个来的, 无法计算Batch统计量, 因此使用的是训练过程中累计的“全局移动平均”均值和方差. 
3.  *解析：D*. A会导致对称性问题；B会导致梯度爆炸/消失；C (Xavier) 适用于Sigmoid/Tanh；D (He初始化) 针对ReLU的一半抑制特性, 方差为 $2/N_"in"$, 是最佳选择. 
4.  *解析：A*. 标准Dropout在训练时只有 $p$ 比例的神经元激活, 导致输出期望变小. 为了在测试时 (全连接) 保持期望一致, 需要将输出乘以 $p$. 
5.  *解析：B*. AdaGrad累积从开始到现在的梯度平方, 分母越来越大, 学习率迅速趋近于0. RMSprop引入衰减系数 $rho$, 只关注最近的梯度平方, 解决了这个问题. 

=== 简答题

1.  *为什么批量归一化 (BN) 不适合循环神经网络 (RNN)？通常使用哪种归一化方法替代？*

2.  *什么是“对称权重现象”？为什么参数不能全部初始化为0？*

3.  *简述 L2 正则化与权重衰减 (Weight Decay) 在优化算法中的关系. *

*简答题解析*

1.  *参考答案*：
    -   *不适合原因*：
        1.  RNN处理的序列长度是动态的, 不同Batch的长度可能不同, BN难以在时间步上计算统计量. 
        2.  RNN在不同时间步共享参数, 但统计分布可能不同, BN效果不佳且存储开销大. 
    -   *替代方法*：通常使用 *层归一化 (Layer Normalization, LN)*. LN 是对单个样本的所有神经元 (特征维度) 进行归一化, 独立于Batch Size和时间步长. 

2.  *参考答案*：
    -   *对称权重现象*：如果在初始化时, 神经网络同一层的所有参数都相同 (例如全为0), 那么在正向传播时, 同一层的所有神经元输出值相同；在反向传播时, 所有权重的梯度更新值也相同. 
    -   *后果*：这意味着无论迭代多少次, 这些神经元学到的特征永远是一样的, 整个层退化为一个神经元, 丧失了神经网络提取不同特征的能力. 

3.  *参考答案*：
    -   在标准的 *随机梯度下降 (SGD)* 中, L2 正则化 (在损失函数加罚项) 和权重衰减 (在更新公式中减去 $lambda w$) 是数学等价的. 
    -   在 *自适应学习率算法 (如 Adam)* 中, 两者不等价. L2 正则化的梯度会被自适应调整 (除以梯度的均方根), 导致正则化力度不均匀；而权重衰减直接作用于参数, 效果更稳定. 

=== 计算题

1.  *批量归一化 (BN) 计算*

    设某层的一个特征维度在 Batch Size $K=2$ 时的输入值为 $z = [2.0, 6.0]^T$. 
    BN 层参数：平滑常数 $epsilon = 0$, 缩放参数 $gamma = 0.5$, 平移参数 $beta = 1.0$. 
    请计算该 BN 层的输出 $a$. 

2.  *动量法 (Momentum) 参数更新*

    已知：
    -   当前梯度 $g_t = 2.0$. 
    -   上一时刻的更新量 (动量)  $Delta theta_(t-1) = -1.0$ (注意：此处定义动量 $v$ 为参数更新量的方向, 即 $Delta theta$). 
    -   当前参数 $theta_(t-1) = 3.0$. 
    -   超参数：学习率 $alpha = 0.1$, 动量系数 $rho = 0.9$. 
    
    使用公式 $Delta theta_t = rho Delta theta_(t-1) - alpha g_t$ 计算：
    (1) 当前时刻的更新量 $Delta theta_t$. 
    (2) 更新后的参数 $theta_t$. 

*计算题解析*

1.  *解答*：
    *(1) 计算均值 $mu_B$*:
    $ mu_B = (2.0 + 6.0) / 2 = 4.0 $

    *(2) 计算方差 $sigma_B^2$*:
    $ sigma_B^2 = 1/2 [(2.0 - 4.0)^2 + (6.0 - 4.0)^2] = 1/2 [4.0 + 4.0] = 4.0 $

    *(3) 标准化 $hat(z)$*:
    $ hat(z)_1 = (2.0 - 4.0) / sqrt(4.0 + 0) = -2.0 / 2.0 = -1.0 $
    $ hat(z)_2 = (6.0 - 4.0) / sqrt(4.0 + 0) = 2.0 / 2.0 = 1.0 $

    *(4) 仿射变换 $a = gamma dot.c hat(z) + beta$*:
    $ a_1 = 0.5 times (-1.0) + 1.0 = 0.5 $
    $ a_2 = 0.5 times (1.0) + 1.0 = 1.5 $

    *结果*：输出为 $[0.5, 1.5]^T$. 

2.  *解答*：
    *(1) 计算更新量 $Delta theta_t$*:
    $ Delta theta_t = 0.9 times (-1.0) - 0.1 times 2.0 $
    $ Delta theta_t = -0.9 - 0.2 = -1.1 $

    *(2) 更新参数 $theta_t$*:
    $ theta_t = theta_(t-1) + Delta theta_t $
    $ theta_t = 3.0 + (-1.1) = 1.9 $
    
    *结果*：更新后的参数为 1.9. 

= 注意力机制与外部记忆

== 考点分析

本章重点在于如何突破传统神经网络在“计算容量”和“长程依赖”上的瓶颈. 除了基础的注意力机制外, *记忆增强网络*和*Hopfield网络*是本章的高阶考点. 

1.  *注意力机制 (Attention)*：
    -   理解注意力机制的本质是“资源分配”和“寻址过程”. 
    -   掌握计算流程：打分函数 (点积、加性等) $arrow.r$ Softmax归一化 $arrow.r$ 加权求和. 
    -   *自注意力 (Self-Attention)*：QKV模型, 并行计算优势, 解决长距离依赖. 

2.  *记忆增强神经网络 (MANN)*：
    -   结构：控制器 (Controller) + 外部记忆 (External Memory) + 读写头. 
    -   寻址：基于内容的寻址 (Content-based Addressing), 利用注意力机制计算相似度. 
    -   *神经图灵机 (NTM)*：具备读写能力, 擦除向量与增加向量的更新机制. 
    -   *端到端记忆网络 (MemN2N)*：通常只读, 多跳 (Multi-Hop) 机制. 

3.  *Hopfield 网络*：
    -   网络结构：全连接、无自环、权重对称的循环网络. 
    -   *赫布规则 (Hebbian Rule)*：权重存储方式. 
    -   *能量函数*：理解网络演化即能量下降的过程, 最终收敛于吸引点 (Attractor). 
    -   应用：联想记忆 (Associative Memory), 模式恢复. 

== 考题预测

=== 选择题

1. 关于 Hopfield 网络的权重矩阵 $W$, 以下哪项描述是必须满足的条件？
  - A. $w_(i j) != w_(j i)$ 且 $w_(i i) != 0$
  - B. $w_(i j) = w_(j i)$ 且 $w_(i i) != 0$
  - C. $w_(i j) != w_(j i)$ 且 $w_(i i) = 0$
  - D. $w_(i j) = w_(j i)$ 且 $w_(i i) = 0$

2. 在注意力机制中, 缩放点积模型 (Scaled Dot-Product) 的打分函数为 $s(x, q) = (x^T q) / sqrt(D)$. 引入分母 $sqrt(D)$ 的主要目的是？
  - A. 减少计算量, 提高推理速度
  - B. 保持输入向量的模长不变
  - C. 防止点积结果过大导致 Softmax 函数进入饱和区, 从而造成梯度消失
  - D. 增加模型的非线性表达能力

3. 关于神经图灵机 (NTM) 的读写操作, 下列说法错误的是？
  - A. 读写操作都是可微的 (Differentiable), 因此可以通过梯度下降训练. 
  - B. 写操作仅包含“增加 (Add)”信息, 不能“删除 (Erase)”信息. 
  - C. 读操作通过注意力分布对记忆片段进行加权平均. 
  - D. 寻址方式主要是基于内容的寻址 (Content-based Addressing). 

4. 端到端记忆网络 (MemN2N) 相比于普通 RNN 的主要改进在于？
  - A. 使用了卷积操作提取特征
  - B. 引入了多跳 (Multi-Hop) 机制和外部大容量记忆, 增强了逻辑推理能力
  - C. 只能处理固定长度的输入序列
  - D. 移除了所有的非线性激活函数

5. 相比于循环神经网络 (RNN), 自注意力模型 (Self-Attention) 在处理长序列时的主要优势是？
  - A. 参数量更少
  - B. 可以并行计算, 且任意两个位置之间的路径长度为 $O(1)$
  - C. 自带位置编码信息
  - D. 能够处理变长序列

=== 简答题

1. *Hopfield 网络是如何实现联想记忆的？请结合“能量函数”和“吸引点”的概念进行说明. *

2. *简述神经图灵机 (NTM) 中“写操作”的具体步骤 (擦除与增加), 并写出相关的数学表达式. *

3. *为什么在深度学习模型 (如 Transformer 或 NTM) 中, 通常使用“软性注意力”而不是“硬性注意力”？*

=== 计算题

*自注意力 (Self-Attention) 输出计算*

  假设输入序列由两个 2 维向量组成：$X = [x_1, x_2]$, 其中 $x_1 = [1, 0]^T, x_2 = [0, 1]^T$. 
  为简化计算, 假设查询矩阵 $W_q$、键矩阵 $W_k$、值矩阵 $W_v$ 均为单位矩阵 $I$. 
  使用点积注意力模型 (不缩放), 计算输出向量 $h_1$. 

== 答案与解析

=== 选择题答案

#table(
  columns: (auto, auto, auto, auto, auto),
  inset: 10pt,
  align: center,
  [*1*], [*2*], [*3*], [*4*], [*5*],
  [D], [C], [B], [B], [B]
)

=== 简答题解析

1. *Hopfield 网络与联想记忆*
  - *机制*：Hopfield 网络通过神经元之间的相互连接存储信息. 网络的每一个状态对应能量函数曲面上的一个点. 
  - *能量函数*：$E = -1/2 s^T W s - b^T s$. 由于权重对称且无自环, 网络在演化过程中能量是单调递减的 (Lyapunov 函数). 
  - *吸引点*：能量函数的局部极小值点称为吸引点. 
  - *联想记忆*：存储的模式被设计为吸引点. 当输入一个带有噪声或不完整的模式 (作为初始状态) 时, 网络会沿着能量下降的方向演化, 最终收敛到最近的吸引点, 从而恢复出原始记忆. 

2. *NTM 的写操作*
  写操作分为两步：先擦除, 后增加. 
  - *擦除 (Erase)*：根据注意力权重 $alpha_t$ 和删除向量 $e_t$, 对记忆 $M_t$ 进行擦除. 
    $ tilde(M)_t = M_t dot (1 - alpha_t e_t) $ (按元素乘)
  - *增加 (Add)*：根据注意力权重 $alpha_t$ 和增加向量 $a_t$, 写入新信息. 
    $ M_(t+1) = tilde(M)_t + alpha_t a_t $
  - *综合公式*：
    $ M_(t+1) = M_t dot (1 - alpha_t e_t) + alpha_t a_t $

3. *软性 vs 硬性注意力*
  - *硬性注意力*：从输入信息中以某种概率采样选择一个位置. 其函数关系不可导, 通常需要使用强化学习训练, 训练难度大. 
  - *软性注意力*：计算所有输入信息的加权平均 (期望). 整个过程是可微的, 可以直接通过反向传播算法进行端到端的梯度更新, 更易于与现有神经网络结合. 

=== 计算题解析

1. 计算 Query, Key, Value:
    由于 $W$ 都是单位矩阵, 所以 $Q = K = V = X$. 
    $q_1 = [1, 0]^T, k_1 = [1, 0]^T, k_2 = [0, 1]^T, v_1 = [1, 0]^T, v_2 = [0, 1]^T$. 

2. 计算注意力打分 (未归一化):
    $ s(x_1, q_1) = k_1^T q_1 = [1, 0] dot [1, 0]^T = 1 $
    $ s(x_2, q_1) = k_2^T q_1 = [0, 1] dot [1, 0]^T = 0 $

3. 计算注意力权重 (Softmax):
    $ alpha_(1,1) = exp(1) / (exp(1) + exp(0)) = e / (e + 1) approx 0.73 $
    $ alpha_(1,2) = exp(0) / (exp(1) + exp(0)) = 1 / (e + 1) approx 0.27 $

4. 计算加权和得到输出 $h_1$:
    $ h_1 = alpha_(1,1) v_1 + alpha_(1,2) v_2 $
    $ h_1 = 0.73 dot [1, 0]^T + 0.27 dot [0, 1]^T $
    $ h_1 = [0.73, 0.27]^T $ (保留 $e$ 的形式作答通常更佳)
    即 $h_1 = [e/(e+1), 1/(e+1)]^T$. 

= 无监督学习

== 考点分析

本章 (第九章) 在课程中通常属于辅助性章节, 考试分值占比一般较低. 主要考察对无监督学习基本思想的理解, 而非复杂的推导. 

*核心考点清单*：
1.  *主成分分析 (PCA)*：理解最大投影方差准则, 知道它是线性降维, 掌握协方差矩阵特征值分解的计算流程. 
2.  *自编码器 (AE)*：理解编码器-解码器结构, 重构误差损失函数. 
3.  *降噪自编码器 (DAE)*：重点掌握其通过“引入噪声”来学习鲁棒特征的原理 (Mask噪声或高斯噪声). 
4.  *稀疏编码*：理解“过完备”基向量 ($M > D$) 和稀疏性约束 ($l_1$ 范数). 
5.  *密度估计*：区分参数 (高斯) 与非参数 (直方图、核密度、KNN) 方法. 特别是核密度 (固定窗宽) 与KNN (固定K值) 的区别. 

== 考题预测

=== 选择题

1. 关于主成分分析 (PCA), 下列说法中*不正确*的是：
  - A. PCA 是一种无监督的线性特征降维方法. 
  - B. PCA 的优化目标是最小化重构误差, 这等价于最大化投影后的方差. 
  - C. PCA 得到的主成分方向是原始数据协方差矩阵的特征向量方向. 
  - D. PCA 为了去除特征间的相关性, 要求投影后的特征对应的特征值必须全部相等. 

2. 降噪自编码器 (Denoising Auto-Encoder, DAE) 的核心思想是：
  - A. 在隐藏层激活值上增加 $l_1$ 正则化项以获得稀疏表示. 
  - B. 强制编码器和解码器的权重矩阵互为转置 (Tie Weights). 
  - C. 将输入 $x$ 损坏为 $tilde(x)$ 后输入网络, 训练目标是使输出尽可能复原原始输入 $x$. 
  - D. 通过逐层堆叠训练 (Layer-Wise Training) 来解决深层网络的梯度消失问题. 

3. 在非参数概率密度估计中, 关于核密度估计 (Kernel Density Estimation / Parzen Window) 与 K 近邻 (KNN) 方法的区别, 描述正确的是：
  - A. 核密度估计固定了区域内的样本数 $K$, 而改变区域体积 $V$. 
  - B. KNN 方法固定了区域体积 $V$, 而改变落入区域的样本数 $K$. 
  - C. 核密度估计通常固定核函数的宽度 (即固定了区域大小), 落入的样本数是随机变量. 
  - D. 随着样本数 $N arrow.r infinity$, KNN 方法中 $K$ 的取值应当保持为 1 以保证精度. 

4. 稀疏编码 (Sparse Coding) 模型通常采用什么方式来寻找数据的稀疏表示？
  - A. 使用维度小于数据维度的基向量组 ($M < D$). 
  - B. 使用过完备的基向量组 ($M > D$), 并在目标函数中加入稀疏性惩罚项. 
  - C. 仅保留协方差矩阵中最大的几个特征值对应的特征向量. 
  - D. 对输入数据进行二值化处理. 

=== 简答题

1. 简述降噪自编码器 (DAE) 相比于普通自编码器 (AE) 的优势, 并解释为什么 DAE 能学习到更鲁棒的特征. 

2. 在概率密度估计中, 参数估计方法与非参数估计方法的主要区别是什么？请列举非参数估计中“直方图方法”的一个主要缺点. 

== 答案与解析

=== 选择题答案

#align(center)[
  #table(
    columns: 4,
    align: center,
    [*1*], [*2*], [*3*], [*4*],
    [D], [C], [C], [B]
  )
]

=== 选择题解析

1. *解析*：D 错误. PCA 投影后的特征 (主成分) 对应协方差矩阵的特征值, 这些特征值通常是从大到小排列的, 代表了数据在不同方向上的方差大小, 绝大多数情况下是不相等的. PCA 的目的正是保留较大的特征值对应的方向, 丢弃较小的. A、B、C 均为 PCA 的正确性质. 

2. *解析*：C 正确. 这是 DAE 的定义. A 是稀疏自编码器；B 是权重绑定策略, 不限于 DAE；D 是堆叠自编码器的训练策略. DAE 依靠“去噪”任务迫使网络捕捉数据流形上的特征. 

3. *解析*：C 正确. 核密度估计 (如 Parzen 窗) 设定固定的窗宽 $H$ (对应体积 $V$), 统计落入的样本数. KNN 则是固定样本数 $K$, 寻找包含这 $K$ 个点的最小体积 $V$. 对于 D 选项, 当 $N arrow.r infinity$ 时, $K$ 也应随之增加, 且 $K/N arrow.r 0$. 

4. *解析*：B 正确. 稀疏编码为了在更丰富的空间中寻找稀疏解, 通常使用过完备基 ($M > D$), 这会导致解不唯一, 因此需要引入稀疏正则项 (如 $l_1$ 范数) 来约束. 

=== 简答题解析

1. *参考答案*：
  - *优势*：普通自编码器如果容量足够大, 可能会简单地学会“复制”输入到输出 (恒等映射), 从而无法提取有效特征. DAE 通过向输入加入噪声, 强迫网络无法单纯靠记忆来复原数据. 
  - *鲁棒性原理*：DAE 必须学习输入数据的内在结构和分布规律, 才能从损坏的数据 (如 $tilde(x)$) 中推断并恢复出原始数据 ($x$). 这使得模型对输入中的微小扰动不敏感, 从而学习到更鲁棒、泛化能力更强的特征表示. 

2. *参考答案*：
  - *主要区别*：参数估计假设数据服从某个已知的概率分布形式 (如高斯分布), 任务是估计该分布的参数 (如均值 $mu$ 和方差 $sigma^2$) ；非参数估计不预先假设数据分布的具体形式, 直接利用数据本身来估计密度. 
  - *直方图缺点*：
    1.  *维度灾难*：随着数据维度 $D$ 增加, 需要的箱子 (Bin) 数量呈指数级增长 ($M^D$), 导致需要极大量的样本才能有效估计. 
    2.  *不连续性*：估计出的密度函数在箱子边界处不连续. 
    3.  *敏感性*：结果对箱子宽度和起始位置的选择非常敏感. 

= 第10章 模型独立的学习方式

== 考点分析

本章 (教材第10章) 主要考察独立于具体网络结构的通用学习范式, 核心目的是解决数据分布不一致、样本少、任务多变等问题. 重点概念如下：

1.  *集成学习 (Ensemble Learning)*
    -   *Bagging (如随机森林)*：通过自助采样 (Bootstrap) 并行训练, 主要降低模型*方差*. 
    -   *Boosting (如 AdaBoost)*：串行训练, 关注错分样本, 主要降低模型*偏差*. 
    -   *AdaBoost*：理解其加性模型与指数损失函数的统计学解释, 掌握样本权重更新机制. 

2.  *半监督学习 (Semi-Supervised Learning)*
    -   *自训练 (Self-Training)*：用高置信度伪标签扩充数据. 
    -   *协同训练 (Co-Training)*：利用多视图 (Multi-view) 数据的互补性, 假设条件独立性. 

3.  *多任务学习 (Multi-Task Learning)*
    -   *共享模式*：硬共享 (Hard Sharing, 共享底层) vs 软共享 (Soft Sharing). 
    -   *作用*：隐式数据增强, 作为归纳偏置提升泛化能力. 

4.  *迁移学习 (Transfer Learning)*
    -   *协变量偏移 (Covariate Shift)*：输入分布 $p(bold(x))$ 变, 后验 $p(y|bold(x))$ 不变. 
    -   *归纳迁移 vs 转导迁移*：区分目标域是否有标签. 
    -   *领域适应 (Domain Adaptation)*：寻找域不变特征 (Domain-Invariant Representation). 

5.  *终身学习 (Lifelong Learning)*
    -   *灾难性遗忘 (Catastrophic Forgetting)*：学新忘旧. 
    -   *EWC 算法*：利用 Fisher 信息矩阵约束重要参数的变化. 

6.  *元学习 (Meta-Learning)*
    -   *MAML*：学习一个易于适应新任务的初始化参数 (Meta-Initialization). 

== 考题预测

=== 选择题

1. 关于集成学习中的 Bagging 和 Boosting 方法, 下列说法错误的是：
  - A. Bagging 方法中, 基模型之间不存在强依赖关系, 可以并行训练. 
  - B. 随机森林 (Random Forest) 是 Bagging 方法的一种典型代表, 它引入了随机特征选择. 
  - C. Boosting 方法通过关注被前一轮基模型误分类的样本来提升性能. 
  - D. Bagging 主要用于降低模型的偏差 (Bias), 而 Boosting 主要用于降低模型的方差 (Variance). 

2. 在迁移学习中, 若源领域和目标领域的输入空间相同 $cal(X)_S = cal(X)_T$, 但输入数据的边际分布不同 $p_S(bold(x)) != p_T(bold(x))$, 且条件概率分布相同 $p_S(y|bold(x)) = p_T(y|bold(x))$, 这种情况被称为：
  - A. 概念偏移 (Concept Shift)
  - B. 协变量偏移 (Covariate Shift)
  - C. 先验偏移 (Prior Shift)
  - D. 标签偏移 (Label Shift)

3. 关于多任务学习 (Multi-task Learning) 的共享模式, 下列描述正确的是：
  - A. 硬共享模式通常在网络的高层进行参数共享, 在底层使用私有模块. 
  - B. 软共享模式显式地强制不同任务使用完全相同的参数矩阵. 
  - C. 硬共享模式通常让不同任务的神经网络共同使用底层的共享模块, 高层使用任务特定模块. 
  - D. 多任务学习会导致模型在所有任务上的性能都下降, 因为任务之间存在干扰. 

4. 终身学习 (Lifelong Learning) 中主要面临的挑战是“灾难性遗忘”, 弹性权重巩固 (EWC) 算法通过引入哪种矩阵来衡量参数对旧任务的重要性？
  - A. 混淆矩阵 (Confusion Matrix)
  - B. 协方差矩阵 (Covariance Matrix)
  - C. Fisher 信息矩阵 (Fisher Information Matrix)
  - D. 雅可比矩阵 (Jacobian Matrix)

5. 模型无关的元学习 (MAML) 的主要目标是：
  - A. 学习一个通用的优化器 (Optimizer) 来替代 SGD. 
  - B. 学习一组模型参数的初始值, 使得模型在面对新任务时能经过少量梯度更新达到较好效果. 
  - C. 将所有任务的数据混合在一起训练一个巨大的通用模型. 
  - D. 通过对抗训练对齐源域和目标域的特征分布. 

=== 简答题

1. 简述 AdaBoost 算法的核心思想及其样本权重调整策略. 

2. 什么是协同训练 (Co-Training)？它需要满足哪两个假设？

3. 解释什么是“灾难性遗忘” (Catastrophic Forgetting), 并简述一种缓解该问题的方法思路. 

== 答案与解析

=== 选择题答案

#align(center)[
  #table(
    columns: (auto, auto, auto, auto, auto),
    inset: 10pt,
    align: horizon,
    [*1*], [*2*], [*3*], [*4*], [*5*],
    [D], [B], [C], [C], [B]
  )
]

=== 选择题解析

1. *解析*：一般认为 Bagging 通过自助采样和平均多个模型主要降低方差 (Variance), 适合高方差模型 (如完全生长的决策树) ；Boosting 通过逐步拟合残差主要降低偏差 (Bias). 故 D 选项描述相反. 

2. *解析*：
   - *协变量偏移*：输入分布 $p(bold(x))$ 变化, 映射关系 $p(y|bold(x))$ 不变 (B 正确). 
   - *概念偏移*：映射关系 $p(y|bold(x))$ 变化. 
   - *先验偏移*：输出标签分布 $p(y)$ 变化. 

3. *解析*：硬共享 (Hard Parameter Sharing) 是多任务学习中最常用的模式, 通常让不同任务共享底层的特征提取器 (如卷积层), 而在高层使用特定的全连接层, 故 C 正确. A 描述反了. 

4. *解析*：EWC 利用 Fisher 信息矩阵近似后验分布的二阶导数 (即 Hessian 矩阵), 以此来衡量参数对旧任务的重要性. 对重要参数的改变施加较大的惩罚. 

5. *解析*：MAML (Model-Agnostic Meta-Learning) 的核心思想是 Meta-Initialization, 即寻找一个对多任务敏感的初始化点, 使得模型只需少量数据和梯度步骤即可适应新任务. 

=== 简答题答案

1. *参考答案*：
  - *核心思想*：AdaBoost 是一种迭代的 Boosting 算法, 它通过串行训练一系列弱分类器来构建强分类器. 每个新的弱分类器都重点关注被前一个弱分类器错分的样本. 
  - *权重调整策略*：
    - 初始化时, 所有样本权重相等. 
    - 在每一轮迭代中, *增加*被当前弱分类器误分类样本的权重, *降低*分类正确样本的权重. 
    - 最终的强分类器是所有弱分类器的加权组合, 分类误差率低的弱分类器拥有更高的投票权重 ($alpha_m$ 更大). 

2. *参考答案*：
  - *定义*：协同训练是一种半监督学习方法, 它利用数据的两个不同视角 (Views) 分别训练两个分类器, 并让它们互相为无标签数据打上伪标签 (互为老师) 来扩充训练集. 
  - *假设*：
    1.  *条件独立性*：给定类别标签时, 两个视角下的特征是条件独立的. 
    2.  *充足与冗余性*：仅使用任何一个视角的数据特征, 都足以训练出一个性能较好的分类器. 

3. *参考答案*：
  - *定义*：在终身学习或连续学习中, 神经网络在学习新任务时, 为了适应新任务的数据分布, 其参数发生大幅变化, 导致在之前已经学会的旧任务上的性能急剧下降甚至完全丧失的现象. 
  - *缓解思路 (如 EWC)*：
    - 在学习新任务时, 对模型参数的更新施加约束. 
    - 识别出对旧任务重要的参数 (例如通过 Fisher 信息矩阵衡量). 
    - 在损失函数中加入正则化项, 惩罚这些重要参数的改变, 允许不重要的参数大幅更新以适应新任务. 
