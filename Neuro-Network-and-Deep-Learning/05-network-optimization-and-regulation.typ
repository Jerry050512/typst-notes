= 网络优化与正则化

/ 优化问题: 损失函数*非凸*; *参数巨多*; 存在*梯度消失*与*梯度爆炸*;
/ 正则化问题: 容易*过拟合*;

== 优化问题

/ 鞍点 (Saddle Points): 鞍点是一阶梯度为零, 但其Hessian矩阵既非半正定也非半负定的点. 鞍点的形状如同一个马鞍, 在某些维度上是局部最高点, 而在另一些维度上则是局部最低点. 随机梯度下降 (SGD) 方法中引入的随机性, 恰好有助于优化过程“冲出”鞍点区域, 从而有效地逃离这些陷阱. 

#figure(
  table(
    columns: 3,
    table.header(
      [*特性*],
      [*平坦最小值 (Flat Minima)*],
      [*尖锐最小值 (Sharp Minima)*],
    ),
    [特征描述],
    [损失函数在一个较宽的邻域内都保持较低的值, 形态平缓. ],
    [损失函数在一个极窄的区域内达到最小值, 两侧迅速攀升, 形态尖锐. ],
    
    [对模型鲁棒性的影响],
    [鲁棒性好. 参数的微小变动不会导致模型性能的剧烈下降. ],
    [鲁棒性差. 参数的微小扰动可能导致损失值大幅增加. ],
    
    [与泛化能力的关系],
    [通常与更好的泛化能力相关. 模型对参数不敏感, 更能适应新数据的变化. ],
    [通常与较差的泛化能力相关. 模型可能过度拟合了训练数据的特定模式. ],
  ),
  caption: [平坦最小值与尖锐最小值的特性对比],
)


/ 局部最小解的等价性 (Equivalence of Local Minima): 一个令人欣慰的经验性发现是, 在大型神经网络中, 我们不必过分执着于寻找全局最小值.  \
  在参数量巨大的神经网络中, 大部分局部最小解在模型性能上是等价的, 它们在测试集上的表现非常相似. 这些性能优良的局部最小解, 其对应的训练损失通常也已经非常接近全局最小损失. 

== 核心算法

神经网络的优化主要使用*梯度下降算法*进行优化, 其中可以分为*批量梯度下降*, *随机梯度下降*, 与*小批量梯度下降*. 常用的优化算法则主要分为两类: i. *调整学习率*, 使得优化更稳定; ii. *梯度估计修正*, 优化训练速度;

=== 小批量梯度下降

梯度下降算法通过计算梯度, 找到损失函数下降最快的方向, 然后沿着这个方向更新参数. 其中批量梯度下降每次更新使用整个训练集的数据计算梯度, 梯度方差小, 但计算量较大; 随机梯度下降每次更新使用一个随机样本计算梯度, 梯度方差大, 但计算量较小; 小批量梯度下降则介于两者之间, 每次更新使用一部分样本计算梯度, 既保证了梯度方差较小, 又保证了计算量适中.

小批量梯度下降是深度学习中最常用的优化算法. 它综合了批量梯度下降 (BGD) 和随机梯度下降 (SGD) 的优点, 在计算效率和收敛稳定性之间取得了平衡. 

==== 算法原理

在机器学习中, 我们的目标是最小化在训练集 $D$ 上的经验风险: 
$ R_("emp")^D (theta) = 1/N sum_(n=1)^N cal(L)(y^(n), f(x^(n); theta)) $

其中 $N$ 是样本总数. 小批量梯度下降的核心在于: 每次参数更新时, 不使用全部样本, 也不只使用单个样本, 而是随机抽取一个包含 $K$ 个样本的小集合 (称为 Mini-batch) 来计算梯度. 

==== 算法流程

设训练集为 $D$, 学习率为 $alpha$, 批量大小为 $K$:
1. *初始化*: 随机初始化参数 $theta$. 
2. *循环迭代*: 直到满足停止条件 (如达到最大回合数或损失收敛): 
  - 将训练集 $D$ 随机打乱 (Shuffle). 
  - 将 $D$ 划分为 $m = N/K$ 个小批量 $D_1, D_2, dots, D_m$. 
  - 对于每一个小批量 $D_t$:
    - 计算该批量的平均梯度: $ g_t = 1/K sum_((x,y) in D_t) nabla_theta cal(L)(y, f(x; theta)) $
    - 更新参数: $ theta arrow.l theta - alpha g_t $

其中$nabla_theta$表示对$theta$求偏导数. 

==== 核心特性对比

#table(
  columns: (1fr, 1fr, 1fr, 1fr),
  inset: 6pt,
  align: center + horizon,
  [*算法类型*], [*单次更新样本数*], [*梯度方差*], [*计算效率*],
  [批量梯度下降 (BGD)], [$N$ (全量)], [极小 (稳定) ], [低 (大数据集难以计算) ],
  [随机梯度下降 (SGD)], [1 (单样)], [极大 (震荡严重) ], [高 (单次计算极快) ],
  [*小批量梯度下降*], [*$K$ (适中)*], [*适中 (较平滑) *], [*高 (利于并行计算) *]
)

==== 批量大小 Batch Size $K$ 的影响

$ 1 "Epoch" = N / K "Iteration" $

- *收敛速度*: 较小的批量 ($K$ 较小) 在相同回合 (Epoch) 内参数更新频率更高, 收敛通常更快. 
- *泛化能力*: 研究表明, 较小的批量有助于模型跳出局部最优解, 收敛到“*平坦最小值*”, 从而提升泛化能力. 
- *计算吞吐*: 较大的批量可以充分利用 GPU 的矩阵运算并行性, 提高单位时间内的训练速度. 

/ 线性缩放规则 (Linear Scaling Rule): 在深度学习中, 我们通常使用线性缩放规则来调整学习率. 具体来说, 如果批量大小从 $K_1$ 增加到 $K_2$, 那么学习率 $alpha$ 应该相应地调整为 $alpha_1 = alpha_2 dot K_1 / K_2$. 

==== 学习率调整策略

在实际应用中, 小批量梯度下降常配合以下技巧: 
- *学习率预热 (Warmup)*: 在训练初期使用极小的学习率, 待梯度稳定后再恢复. 
- *学习率衰减 (Decay)*: 随着迭代次数增加, 逐渐减小学习率以保证最后能收敛到最优值附近. 

=== 学习率调整

$ theta <- theta - alpha g_t $
- 学习率过大则不收敛; 
- 学习率过小则收敛速度慢; 

==== 学习率衰减 (Learning Rate Decay)

学习率衰减是最基础的策略, 即随着迭代次数或回合 (Epoch) 的增加, 逐渐减小学习率. 
- *逆时衰减*: $alpha_t = alpha_0 / (1 + beta t)$, 其中 $beta$ 为衰减率, $t$ 为迭代次数. 
- *指数衰减*: $alpha_t = alpha_0 beta^t$, 其中 $beta < 1$. 
- *常数衰减*: 每隔一定的 Epoch, 将学习率乘以一个常数 (如 $0.1$) , 或分段常数衰减, 每段衰减常数不一样. 
- *自然指数衰减*: $alpha_t = alpha_0 exp(- beta t)$. 
- *余弦衰减*: $alpha_t = alpha_0 (1 + cos(pi t/T)) / 2$. 

==== 学习率预热 (Learning Rate Warmup)

在训练初期, 由于参数是随机初始化的, 梯度往往非常大. 如果此时学习率较大, 可能导致模型震荡. 
- *原理*: 在最初的若干个迭代步中, 将学习率从一个极小值逐渐线性增加到预设的初始学习率. 
- *作用*: 使模型在训练初期更平稳地探索参数空间. 

常用方法是*逐渐预热* (Gradual Warmup), 即从 $alpha_0$ 线性增加到 $alpha_1$, 然后再进行学习率衰减. 

==== 周期性学习率调整 (Cyclical Learning Rate)

不同于传统的单调递减策略, 周期性调整让学习率在一定范围内循环波动, 从而使模型具有更好的探索能力. 

- *循环学习率 (Cyclical Learning Rate, CLR)*: 
  设置一个学习率范围 $[alpha_"min", alpha_"max"]$, 让学习率在两个边界之间周期性地线性变化. 这种方法可以帮助模型跳出鞍点或局部最优解, 且不需要像固定学习率那样反复试验最优初始值.  \
  例如三角循环学习率可以将最大值线性缩小, 也可以每次保持不变. 

- *带热重启的随机梯度下降 (SGDR)*: 
  SGDR (Stochastic Gradient Descent with Warm Restarts) 常与 *余弦退火 (Cosine Annealing)* 配合使用. 其核心在于: 
  - *退火阶段*: 学习率按余弦函数平滑下降至最小值. 
    $ alpha_t = alpha_"min"^i + 1/2 (alpha_"max"^i - alpha_"min"^i) (1 + cos(pi t / T_i)) $
  - *热重启 (Warm Restart)*: 当学习率下降到最小值后, 立即将其重置为初始的最大值, 开始下一个周期的训练. 
  
- *作用与优势*: 
  1. *跳出局部最优*: 热重启时学习率突然增大, 产生的“震荡”能帮助模型从当前的局部最优坑穴中跳出, 去寻找更好的平坦最小值. 
  2. *训练稳定性*: 余弦退火保证了在一个周期内部, 模型能平滑地向最优解收敛. 
  3. *效率*: 通常能比固定学习率策略在更短的 Epoch 内达到更好的精度. 

==== 自适应学习率 (Adaptive Learning Rate)

通过计算历史梯度信息来为每个参数单独设置学习率. 
- *AdaGrad*: 累积历史梯度的平方和, 对频繁更新的参数设置较小学习率. 
- *RMSprop*: 在 AdaGrad 基础上引入衰减系数, 只考虑近期梯度的信息, 解决后期学习率过早消失的问题. 
- *Adam*: 结合了动量 (Momentum) 和 RMSprop, 是目前工业界最常用的自适应优化算法. 

前两者的参数更新差值都是用下式计算得到 $ Delta theta_t = - alpha / sqrt(G_t + epsilon) dot.o g_t $
其中, 
- AdaGrad 通过计算梯度平方累计值, 即 $ G_t = G_(t - 1) + g_t dot.o g_t $
- RMSprop 则在 AdaGrad 的基础上引入了衰减系数, *指数衰减移动平均*, 即 $ G_t = beta G_(t - 1) + (1 - beta) g_t dot.o g_t $

=== 梯度估计修正

在小批量梯度下降中, 由于采样的随机性, 梯度的估计往往包含噪声. 通过引入历史梯度的信息, 可以有效平滑参数更新轨迹, 加速收敛. 

==== 动量法 (Momentum)

动量法通过引入一个动量项 (速度) 来积累之前的梯度信息. 
- *计算公式*: 
  $ v_t = rho v_(t-1) + g_t $
  $ theta_(t+1) = theta_t - alpha v_t $
  其中 $rho$ 为动量因子 (通常设为 0.9), $v_t$ 是对梯度的指数加权平均. 
- *作用*: 在梯度方向一致的维度上加速, 在梯度方向频繁震荡的维度上减速, 从而减少震荡, 加快收敛. 

==== Nesterov 加速梯度 (Nesterov Accelerated Gradient, NAG)

NAG 是对动量法的改进, 其核心思想是“瞻前顾后”, 即在当前位置先按照动量方向“走一步”, 再计算该位置的梯度. 
- *更新规则*: 
  $ v_t = rho v_(t-1) + g_t (theta_t - alpha rho v_(t-1)) $
  $ theta_(t+1) = theta_t - alpha v_t $
- *区别*: 动量法计算的是当前位置的梯度, 而 NAG 计算的是预估未来位置的梯度. 这使得 NAG 具有更好的预见性, 能防止更新过头. 

==== Adam 算法 (Adaptive Moment Estimation)

$ "Adam" approx "Momentum" + "RMSprop" $

Adam 结合了动量法和自适应学习率 (RMSprop) 的优点, 是目前最常用的优化算法之一. 
- *核心公式*: 
  1. 计算梯度的一阶矩 (动量) 和二阶矩 (未中心化的方差): 
     $ M_t = beta_1 M_(t-1) + (1 - beta_1) g_t $
     $ G_t = beta_2 G_(t-1) + (1 - beta_2) g_t dot.o g_t $
  2. 偏差修正 (解决初始阶段 $M_t, G_t$ 偏向 0 的问题): 
     $ hat(M)_t = M_t / (1 - beta_1^t), quad hat(G)_t = G_t / (1 - beta_2^t) $
  3. 参数更新: 
     $ theta_(t+1) = theta_t - alpha / sqrt(hat(G)_t + epsilon) hat(M)_t $
- *特点*: 能够为不同的参数自适应地调节学习率, 同时利用动量平滑梯度, 通常对超参数不敏感. 

==== 梯度截断 (Gradient Clipping)

梯度截断是一种防止梯度爆炸的简单而有效的策略. 其核心思想是当梯度的范数超过某个阈值时, 将其截断到该阈值. 

$ g_t = "clip"(g_t, -c, c) $

=== 参数初始化方法对比

参数初始化的主要目的是维持神经网络层与层之间信号的方差, 避免梯度消失或爆炸. 

#figure(
  table(
    columns: (auto, 2fr, 1fr, 2.5fr),
    align: center + horizon,
    [*初始化方法*], [*核心公式 / 分布*], [*适用场景*], [*主要特点*],
    [固定方差], [$W ~ cal(N)(0, sigma^2)$ \ 或 $U(-r, r)$], [小型网络, 浅层模型], [这种方法通常从一个固定方差的分布 (如高斯分布或均匀分布) 中采样. 简单但易导致深层梯度不稳定],
    [Xavier (Glorot)], [$sigma^2 = 2 / (n_"in" + n_"out")$], [Sigmoid, Tanh \ 等线性/对称激活], [保持输入输出方差一致, 其中 $n_"in"$ 和 $n_"out"$ 分别是当前层的输入和输出维度. ],
    [He (Kaiming)], [$sigma^2 = 2 / n_"in"$], [ReLU, Leaky ReLU], [由于 ReLU 激活函数会将一半的输入设为 0, 导致方差减半, 因此 He 初始化将方差扩大两倍. 补偿了 ReLU 带来的方差减半],
    [正交初始化], [$W W^T = I$], [RNN, 极深层 CNN], [保持梯度范数, 缓解长距离依赖问题]
  ),
  caption: [常见参数初始化方法总结],
)

=== 数据预处理 (Data Preprocessing)

虽然神经网络具有一定的尺度不变性, 但输入特征尺度差异过大会导致损失函数的等高线呈椭球状, 增加优化难度. 通过预处理, 可以使各个维度的特征具有相似的取值区间, 从而加速收敛. 

==== 最小最大归一化 (Min-Max Normalization)

将特征缩放到固定的区间 (通常是 $[0, 1]$). 
- *计算公式*: $ hat(x) = (x - x_min) / (x_max - x_min) $
- *特点*: 对原始数据的分布影响较小, 但在有离群值 (Outliers) 时效果较差, 因为极大值会压缩正常数据的取值范围. 

==== 标准化 (Standardization / Z-Score Normalization)

将特征转换为均值为 0、方差为 1 的分布. 
- *计算公式*: $ hat(x) = (x - mu) / sigma $
- *特点*: 最常用的预处理方法. 它不仅能处理量纲不一的问题, 还能使特征分布更符合激活函数 (如 $tanh$) 的非饱和区, 有利于梯度传播. 

==== 白化 (Whitening)

白化是一种更高级的预处理方法, 旨在消除特征之间的相关性. 
- *核心操作*: 
  1. 先进行标准化, 使均值为 0. 
  2. 利用主成分分析 (PCA) 旋转坐标轴, 消除冗余相关性. 
  3. 对每个维度进行缩放, 使特征协方差矩阵为单位矩阵 $I$. 
- *作用*: 白化可以使输入数据在空间中分布更“圆”, 进一步降低特征间的冗余, 但计算开销较大. 

=== 逐层归一化 (Layer-wise Normalization)

在深度神经网络中, 前层参数的更新会改变后层输入的分布, 这种现象称为 *内部协变量偏移 (Internal Covariate Shift)*. 逐层归一化通过将各层神经元的净输入或激活值转换到统一的分布上, 极大地改善了深层网络的训练稳定性. 

- *加速收敛*: 允许使用更大的学习率, 而不必担心梯度消失或爆炸. 
- *降低敏感性*: 减轻了模型对参数初始化方案的依赖. 
- *正则化效果*: 引入了一定的随机噪声 (尤其在批量归一化中), 有助于提高模型的泛化能力. 

对于每一层的净输入 $z$, 归一化操作通常包含两个步骤: 
1. *标准化*: 将 $z$ 变换为均值为 0、方差为 1 的分布. 
   $ hat(z) = (z - mu) / sqrt(sigma^2 + epsilon) $
2. *再参数化 (Scaling and Shifting)*: 为了恢复网络的表达能力, 引入可学习的参数 $gamma$ 和 $beta$:
   $ y = gamma hat(z) + beta $
   这样模型可以自动学习是否需要还原原始分布. 

#figure(
  table(
    columns: (auto, 2fr, 2fr),
    align: center + horizon,
    [*方法*], [*归一化对象 (统计量计算范围)*], [*适用场景*],
    [批量归一化 (Batch Norm)], [在*小批量 (Batch)* 维度上计算均值和方差. ], [卷积神经网络 (CNN), \ 计算机视觉任务],
    [层归一化 (Layer Norm)], [在*单个样本的所有特征*维度上计算均值和方差. ], [循环神经网络 (RNN), \ Transformer (NLP任务)],
  ),
  caption: [批量归一化与层归一化的区别],
)

重点理解: BN 与 LN 的区别
- *Batch Normalization (BN)*: 强依赖于 Batch Size. 在训练时记录全局均值和方差供测试时使用. 对于动态网络 (如 RNN) 或小 Batch 场景效果较差. 
- *Layer Normalization (LN)*: 均值和方差仅取决于当前单个样本. 它不依赖 Batch 大小, 在处理变长序列数据 (如自然语言处理) 时表现出卓越的稳定性. 

=== 超参数优化 (Hyperparameter Optimization)

超参数是定义模型结构和训练算法控制权标的参数, 无法通过梯度下降自动更新. 超参数优化的目标是寻找一组配置, 使模型在验证集上的性能达到最优. 

#figure(
  table(
    columns: (1fr, 2.5fr, 1.5fr),
    inset: 7pt,
    align: (center + horizon, left + horizon, center + horizon),
    fill: (x, y) => if y == 0 { gray.lighten(80%) },
    [*方法*], [*核心原理*], [*评价*],
    [网格与随机搜索 (Grid/Random)], [在空间中按步长或随机采样尝试. ], [随机搜索效率通常高于网格. ],
    [贝叶斯优化 (Bayesian Opt)], [利用已评估点构建概率模型 (如高斯过程), 预测并平衡“探索”与“利用”. ], [自适应强, 实验次数少. ],
    [动态资源分配 (Hyperband)], [提前终止表现不佳的超参数配置 (早停), 将资源倾斜给潜力模型. ], [高效利用计算资源. ],
    [神经架构搜索 (NAS)], [利用子网络性能作为反馈, 训练控制器自动设计模型结构. ], [高度自动化 (元学习). ]
  ),
  caption: [常见超参数优化方法总结],
)

== 网络正则化核心方法

正则化通过对模型施加约束来限制其复杂度. 对于表达能力极强的深度网络, 正则化是确保模型从“拟合数据”走向“理解规律”的关键. 

=== $ell_1$ 与 $ell_2$ 正则化

这是最基础的正则化技术, 通过在损失函数中引入参数范数惩罚项来约束搜索空间. 

- *$ell_1$ 正则化 (Lasso)*: 惩罚项为参数绝对值之和 $lambda ||theta||_1$. 
  - *特性*: 倾向于产生*稀疏解* (许多参数变为 0), 具有自动特征选择的功能. 
  - *几何形状*: 在参数空间中呈菱形. 
- *$ell_2$ 正则化 (Ridge)*: 惩罚项为参数平方和 $1/2 lambda ||theta||_2^2$. 
  - *特性*: 使权重普遍变小且分散 (*权重衰减*), 防止模型过度依赖个别特征. 
  - *几何形状*: 在参数空间中呈圆形. 

#figure(
  table(
    columns: (1fr, 1.5fr, 1.5fr),
    inset: 6pt,
    align: center + horizon,
    fill: (x, y) => if y == 0 { gray.lighten(80%) },
    [*特性*], [*$ell_1$ 正则化*], [*$ell_2$ 正则化*],
    [核心约束], [参数绝对值之和], [参数平方和],
    [解的性质], [稀疏解 (特征选择) ], [平滑解 (权重压缩) ],
    [几何形状], [菱形 (易交在轴上) ], [圆形 (各向同性) ]
  ),
  caption: [L1 与 L2 正则化对比]
)



=== 权重衰减 (Weight Decay)

权重衰减在每次迭代时按比例缩减参数值: $theta_t arrow.l (1 - beta) theta_(t-1) - alpha g_t$. 
- *与 $ell_2$ 的关系*: 在标准 SGD 下, $ell_2$ 正则化等价于权重衰减. 但在 Adam 等自适应优化器中, 两者的实现逻辑不同, 需区分对待 (如使用 AdamW 优化器). 

=== 丢弃法 (Dropout)

Dropout 通过在训练时随机“关闭”一部分神经元 (概率为 $p$) 来增强模型的鲁棒性. 

- *集成学习视角*: 每次丢弃相当于采样了一个不同的子网络, 最终测试阶段相当于对海量共享参数的子网络进行“模型集成”. 
- *贝叶斯视角*: 被视为对参数后验分布的一种近似贝叶斯推断 (MC Dropout), 赋予了模型不确定性估计的能力. 
- *注意*: 在 RNN 中, 不能直接在时间步的循环连接上使用 Dropout, 否则会破坏长程记忆; 通常仅应用于非循环连接. 

=== 标签平滑 (Label Smoothing)

针对模型“过分自信”导致的过拟合, 将 one-hot 硬标签转换为软标签. 
- *公式*: 将 $[0, 0, 1]$ 转换为 $[epsilon / (K-1), epsilon / (K-1), 1 - epsilon]$. 
- *作用*: 防止模型将正确类别的概率强推向 1, 抑制权重过大, 在有噪声的数据集上表现尤为稳健. 

== 考题与考点预测

=== 核心考点预测

根据教材第7章内容, 本章主要通过“网络优化”和“正则化”两个维度来提升深度模型的性能. 

1.  *高维非凸优化挑战*：
    -   *鞍点 (Saddle Point)*：在高维空间中, 梯度为0的点主要是鞍点而非局部极小值. 鞍点的特征是一阶梯度为0, 但Hessian矩阵非正定. 
    -   *平坦最小值 vs 尖锐最小值*：平坦最小值 (Flat Minima) 通常对应更好的泛化能力. 

2.  *优化算法 (Optimization Algorithms)*：
    -   *动量法 (Momentum)*：利用历史梯度的加权移动平均 (积累动量) 来加速收敛, 抑制振荡. 
    -   *自适应学习率算法*：
        -   *AdaGrad*：累积梯度平方, 导致学习率单调递减, 容易过早停止. 
        -   *RMSprop*：引入衰减率 $rho$, 使用指数移动平均计算梯度平方, 解决AdaGrad学习率过早消失问题. 
        -   *Adam*：结合了动量法 (一阶矩) 和RMSprop (二阶矩), 并进行了偏差修正. 

3.  *参数初始化 (Initialization)*：
    -   *对称权重现象*：全0初始化的后果. 
    -   *Xavier初始化*：保持每一层输出方差一致, 适用于Sigmoid/Tanh激活函数. 
    -   *He初始化 (Kaiming Init)*：适用于ReLU及其变种, 方差为 $2 / N_"in"$. 

4.  *逐层归一化 (Normalization) - 重中之重*：
    -   *Batch Normalization (BN)*：
        -   位置：仿射变换之后, 激活函数之前. 
        -   训练 vs 测试：训练用Batch统计量, 测试用全局滑动平均统计量. 
        -   参数：可学习的拉伸 $gamma$ 和平移 $beta$. 
    -   *Layer Normalization (LN)*：对单个样本的所有神经元进行归一化, 独立于Batch Size, 更适合RNN. 

5.  *正则化 (Regularization)*：
    -   *Dropout*：训练时随机“关闭”神经元 (除以 $1-p$ 或测试时乘以 $p$), 集成学习视角的解释. 
    -   *权重衰减 (Weight Decay)*：等价于L2正则化 (在标准SGD下). 
    -   *标签平滑 (Label Smoothing)*：防止模型对硬标签 (One-hot) 过拟合. 

=== 考题预测

==== 选择题

1. 在深度神经网络的高维非凸优化曲面上, 梯度为0的点最常见的是哪种点, 导致优化算法容易陷入停滞？
  - A. 全局极小值 (Global Minima)
  - B. 局部极小值 (Local Minima)
  - C. 鞍点 (Saddle Point)
  - D. 尖锐极大值 (Sharp Maxima)
  
  *答案：C*
  *解析：* 在高维空间中, 大部分梯度为0的点是鞍点 (在一个维度是极小值, 在另一个维度是极大值). 随着维度增加, 局部极小值的概率指数级降低, 鞍点成为优化的主要障碍. 

2. 关于批量归一化 (Batch Normalization, BN), 下列说法*错误*的是？
  - A. BN通常放置在仿射变换 (如 $W x + b$) 之后, 非线性激活函数之前. 
  - B. BN 引入了两个可学习的参数 $gamma$ 和 $beta$ 以恢复网络的表达能力. 
  - C. 在推理 (Testing/Inference) 阶段, BN 层使用当前输入 Batch 的均值和方差进行归一化. 
  - D. BN 可以缓解梯度消失问题, 允许使用更大的学习率, 从而加速收敛. 

  *答案：C*
  *解析：* C错误. 在推理 (测试) 阶段, 单个Batch可能太小导致统计不稳定, 或者只是单个样本输入. 因此, 推理时使用的是在训练过程中计算的“全局移动平均”均值和方差, 而不是当前Batch的统计量. 

3. 在训练使用 ReLU 激活函数的深层神经网络时, 为了防止梯度消失或爆炸, 最推荐使用的参数初始化方法是？
  - A. 标准高斯分布初始化 $cal(N)(0, 1)$
  - B. 均匀分布初始化 $[-0.1, 0.1]$
  - C. Xavier 初始化 (Glorot Initialization)
  - D. He 初始化 (Kaiming Initialization)

  *答案：D*
  *解析：* A和B容易导致梯度爆炸或消失；C (Xavier) 适用于Sigmoid或Tanh函数；D (He初始化) 考虑到ReLU会将一半神经元置为0, 因此将方差放大为 Xavier 的2倍 ($2/N_"in"$), 是针对ReLU的最佳实践. 

4. 关于 Dropout (丢弃法), 假设训练时的保留概率为 $p$ (即神经元以概率 $p$ 存活), 若采用标准的 Dropout 实现 (训练时输出不缩放), 在测试阶段应该如何处理神经元的输出？
  - A. 输出值乘以 $p$
  - B. 输出值除以 $p$
  - C. 输出值乘以 $(1-p)$
  - D. 不做任何处理

  *答案：A*
  *解析：* 在训练时, 只有比例为 $p$ 的神经元被激活. 为了在测试时保持期望值一致 (Test阶段所有神经元都激活), 需要将输出值乘以 $p$ 进行缩放. 
  *(注：如果是Inverted Dropout, 即训练时除以 $p$, 则测试时选D)*

5. 下列哪种优化算法通过计算梯度平方的指数加权移动平均来调整学习率, 从而解决了 AdaGrad 学习率过早衰减的问题？
  - A. 动量法 (Momentum)
  - B. RMSprop
  - C. SGD
  - D. Nesterov

  *答案：B*
  *解析：* AdaGrad累积所有历史梯度平方, 导致分母一直增加, 学习率趋向0. RMSprop 引入衰减系数, 只关注最近的梯度平方, 解决了这个问题. 

==== 简答题

1. *简述批量归一化 (Batch Normalization) 为什么不适合循环神经网络 (RNN), 以及通常使用什么方法替代？*

  *参考答案：*
  - *原因 1 (动态长度)*：RNN 处理的序列长度是动态变化的. 如果使用 BN, 需要为每一个时间步 (Time Step) 存储和维护单独的均值和方差统计量. 对于测试时出现的比训练集更长的序列, 无法处理. 
  - *原因 2 (参数共享)*：RNN 在不同时间步共享权重, 但不同时间步的统计特征分布可能差异很大, BN 强行对不同时间步做归一化效果不佳. 
  - *替代方案*：通常使用 *层归一化 (Layer Normalization, LN)*. LN 是在特征维度 (Feature dim) 上对单个样本的所有神经元进行归一化, 不依赖于 Batch Size, 也不依赖于时间步, 因此非常适合 RNN. 

2. *什么是“内部协变量偏移 (Internal Covariate Shift)”, 逐层归一化是如何解决这个问题的？*

  *参考答案：*
  - *概念*：在深度神经网络训练过程中, 由于前层参数的更新, 导致后层神经元输入数据的分布不断发生变化. 这使得后层网络需要不断适应新的分布, 降低了训练效率. 
  - *解决*：逐层归一化 (如 BN) 强制将每一层神经元的输入分布拉回到均值为0、方差为1的标准正态分布附近. 这使得输入分布保持相对稳定, 模型可以使用更大的学习率, 并且对参数初始化不那么敏感. 同时, 通过引入可学习参数 $gamma, beta$, 保证了模型并未完全丢失非线性表达能力. 

3. *请说明 L2 正则化与权重衰减 (Weight Decay) 的联系与区别. *

  *参考答案：*
  - *联系*：在标准的随机梯度下降 (SGD) 算法中, L2 正则化 (在损失函数中加入 $lambda / 2 ||w||^2$) 对参数求导后, 其更新公式与权重衰减 (在更新时直接减去 $lambda w$) 在数学上是完全等价的. 
  - *区别*：在复杂的自适应优化算法 (如 Adam) 中, 两者不等价. L2 正则化的梯度会被归一化 (除以梯度的均方根), 导致正则化力度被减弱；而权重衰减是直接作用于参数更新步骤, 不经过自适应梯度的调整. 因此在 Adam 中, 应当使用解耦的权重衰减 (Decoupled Weight Decay, 如 AdamW). 

==== 计算题

1. *批量归一化 (BN) 计算*

  在一个神经网络层中, 设某个特征维度在 Batch Size $K=2$ 时的输入值为 $z = [1.0, 3.0]^T$. 
  假设 BN 层处于训练模式, 且为了数值稳定性 $epsilon = 0$. 
  该层学习到的缩放参数 $gamma = 2$, 平移参数 $beta = 0.5$. 
  请计算该 BN 层的最终输出 $a$. 

  *解题步骤：*

  1. 计算小批量的均值 $mu_B$：
     $ mu_B = 1 / K sum_(k=1)^K z^((k)) = (1.0 + 3.0) / 2 = 2.0 $

  2. 计算小批量的方差 $sigma_B^2$ (注意教材公式 7.54 使用的是 $1/K$ 的总体方差公式)：
     $ sigma_B^2 = 1 / K sum_(k=1)^K (z^((k)) - mu_B)^2 = 1 / 2 * [(1.0 - 2.0)^2 + (3.0 - 2.0)^2] $
     $ sigma_B^2 = 1 / 2 * [1.0 + 1.0] = 1.0 $

  3. 进行标准化 $hat(z)$：
     $ hat(z)^((1)) = (1.0 - 2.0) / sqrt(1.0 + 0) = -1.0 $
     $ hat(z)^((2)) = (3.0 - 2.0) / sqrt(1.0 + 0) = 1.0 $

  4. 进行缩放和平移变换 $y = gamma dot.c hat(z) + beta$：
     $ a^((1)) = 2 * (-1.0) + 0.5 = -1.5 $
     $ a^((2)) = 2 * (1.0) + 0.5 = 2.5 $

  *最终结果：* 输出向量为 $[-1.5, 2.5]^T$. 

2. *动量法 (Momentum) 参数更新*

  假设损失函数关于参数 $theta$ 的梯度为 $g$. 当前时刻 $t$, 参数 $theta_(t-1) = 5.0$, 上一时刻积累的动量 $v_(t-1) = 1.0$. 
  当前计算出的梯度 $g_t = 4.0$. 
  超参数设置：学习率 $alpha = 0.1$, 动量衰减因子 $rho = 0.9$. 
  请利用动量法公式计算参数的更新量 $Delta theta_t$ 和更新后的参数 $theta_t$. 

  *(注：依据教材公式 7.21, 更新方向定义为负梯度的加权移动平均)*

  *解题步骤：*

  1. 计算参数更新差值 $Delta theta_t$ (即积累的动量与当前梯度的结合)：
     根据公式：$Delta theta_t = rho Delta theta_(t-1) - alpha g_t$
     这里 $v_(t-1)$ 即对应上一时刻的更新量 $Delta theta_(t-1)$ (假设方向一致). 
     
     $ Delta theta_t = 0.9 * 1.0 - 0.1 * 4.0 $
     $ Delta theta_t = 0.9 - 0.4 = 0.5 $

  2. 更新参数 $theta_t$：
     $ theta_t = theta_(t-1) + Delta theta_t $
     $ theta_t = 5.0 + 0.5 = 5.5 $

  *最终结果：* $theta_t = 5.5$. 