= 网络优化与正则化

/ 优化问题: 损失函数*非凸*; *参数巨多*; 存在*梯度消失*与*梯度爆炸*;
/ 正则化问题: 容易*过拟合*;

== 优化问题

/ 鞍点 (Saddle Points): 鞍点是一阶梯度为零, 但其Hessian矩阵既非半正定也非半负定的点. 鞍点的形状如同一个马鞍, 在某些维度上是局部最高点, 而在另一些维度上则是局部最低点. 随机梯度下降 (SGD) 方法中引入的随机性, 恰好有助于优化过程“冲出”鞍点区域, 从而有效地逃离这些陷阱. 

#figure(
  table(
    columns: 3,
    table.header(
      [*特性*],
      [*平坦最小值 (Flat Minima)*],
      [*尖锐最小值 (Sharp Minima)*],
    ),
    [特征描述],
    [损失函数在一个较宽的邻域内都保持较低的值, 形态平缓. ],
    [损失函数在一个极窄的区域内达到最小值, 两侧迅速攀升, 形态尖锐. ],
    
    [对模型鲁棒性的影响],
    [鲁棒性好. 参数的微小变动不会导致模型性能的剧烈下降. ],
    [鲁棒性差. 参数的微小扰动可能导致损失值大幅增加. ],
    
    [与泛化能力的关系],
    [通常与更好的泛化能力相关. 模型对参数不敏感, 更能适应新数据的变化. ],
    [通常与较差的泛化能力相关. 模型可能过度拟合了训练数据的特定模式. ],
  ),
  caption: [平坦最小值与尖锐最小值的特性对比],
)


/ 局部最小解的等价性 (Equivalence of Local Minima): 一个令人欣慰的经验性发现是, 在大型神经网络中, 我们不必过分执着于寻找全局最小值.  \
  在参数量巨大的神经网络中, 大部分局部最小解在模型性能上是等价的, 它们在测试集上的表现非常相似. 这些性能优良的局部最小解, 其对应的训练损失通常也已经非常接近全局最小损失. 

== 核心算法

神经网络的优化主要使用*梯度下降算法*进行优化, 其中可以分为*批量梯度下降*, *随机梯度下降*, 与*小批量梯度下降*. 常用的优化算法则主要分为两类: i. *调整学习率*, 使得优化更稳定; ii. *梯度估计修正*, 优化训练速度;

=== 小批量梯度下降

梯度下降算法通过计算梯度, 找到损失函数下降最快的方向, 然后沿着这个方向更新参数. 其中批量梯度下降每次更新使用整个训练集的数据计算梯度, 梯度方差小, 但计算量较大; 随机梯度下降每次更新使用一个随机样本计算梯度, 梯度方差大, 但计算量较小; 小批量梯度下降则介于两者之间, 每次更新使用一部分样本计算梯度, 既保证了梯度方差较小, 又保证了计算量适中.

小批量梯度下降是深度学习中最常用的优化算法. 它综合了批量梯度下降 (BGD) 和随机梯度下降 (SGD) 的优点, 在计算效率和收敛稳定性之间取得了平衡. 

==== 算法原理

在机器学习中, 我们的目标是最小化在训练集 $D$ 上的经验风险: 
$ R_("emp")^D (theta) = 1/N sum_(n=1)^N cal(L)(y^(n), f(x^(n); theta)) $

其中 $N$ 是样本总数. 小批量梯度下降的核心在于: 每次参数更新时, 不使用全部样本, 也不只使用单个样本, 而是随机抽取一个包含 $K$ 个样本的小集合 (称为 Mini-batch) 来计算梯度. 

==== 算法流程

设训练集为 $D$, 学习率为 $alpha$, 批量大小为 $K$:
1. *初始化*: 随机初始化参数 $theta$. 
2. *循环迭代*: 直到满足停止条件 (如达到最大回合数或损失收敛): 
  - 将训练集 $D$ 随机打乱 (Shuffle). 
  - 将 $D$ 划分为 $m = N/K$ 个小批量 $D_1, D_2, dots, D_m$. 
  - 对于每一个小批量 $D_t$:
    - 计算该批量的平均梯度: $ g_t = 1/K sum_((x,y) in D_t) nabla_theta cal(L)(y, f(x; theta)) $
    - 更新参数: $ theta arrow.l theta - alpha g_t $

其中$nabla_theta$表示对$theta$求偏导数. 

==== 核心特性对比

#table(
  columns: (1fr, 1fr, 1fr, 1fr),
  inset: 6pt,
  align: center + horizon,
  [*算法类型*], [*单次更新样本数*], [*梯度方差*], [*计算效率*],
  [批量梯度下降 (BGD)], [$N$ (全量)], [极小 (稳定) ], [低 (大数据集难以计算) ],
  [随机梯度下降 (SGD)], [1 (单样)], [极大 (震荡严重) ], [高 (单次计算极快) ],
  [*小批量梯度下降*], [*$K$ (适中)*], [*适中 (较平滑) *], [*高 (利于并行计算) *]
)

==== 批量大小 Batch Size $K$ 的影响

$ 1 "Epoch" = N / K "Iteration" $

- *收敛速度*: 较小的批量 ($K$ 较小) 在相同回合 (Epoch) 内参数更新频率更高, 收敛通常更快. 
- *泛化能力*: 研究表明, 较小的批量有助于模型跳出局部最优解, 收敛到“*平坦最小值*”, 从而提升泛化能力. 
- *计算吞吐*: 较大的批量可以充分利用 GPU 的矩阵运算并行性, 提高单位时间内的训练速度. 

/ 线性缩放规则 (Linear Scaling Rule): 在深度学习中, 我们通常使用线性缩放规则来调整学习率. 具体来说, 如果批量大小从 $K_1$ 增加到 $K_2$, 那么学习率 $alpha$ 应该相应地调整为 $alpha_1 = alpha_2 dot K_1 / K_2$. 

==== 学习率调整策略

在实际应用中, 小批量梯度下降常配合以下技巧: 
- *学习率预热 (Warmup)*: 在训练初期使用极小的学习率, 待梯度稳定后再恢复. 
- *学习率衰减 (Decay)*: 随着迭代次数增加, 逐渐减小学习率以保证最后能收敛到最优值附近. 

=== 学习率调整

$ theta <- theta - alpha g_t $
- 学习率过大则不收敛; 
- 学习率过小则收敛速度慢; 

==== 学习率衰减 (Learning Rate Decay)

学习率衰减是最基础的策略, 即随着迭代次数或回合 (Epoch) 的增加, 逐渐减小学习率. 
- *逆时衰减*: $alpha_t = alpha_0 / (1 + beta t)$, 其中 $beta$ 为衰减率, $t$ 为迭代次数. 
- *指数衰减*: $alpha_t = alpha_0 beta^t$, 其中 $beta < 1$. 
- *常数衰减*: 每隔一定的 Epoch, 将学习率乘以一个常数 (如 $0.1$) , 或分段常数衰减, 每段衰减常数不一样. 
- *自然指数衰减*: $alpha_t = alpha_0 exp(- beta t)$. 
- *余弦衰减*: $alpha_t = alpha_0 (1 + cos(pi t/T)) / 2$. 

==== 学习率预热 (Learning Rate Warmup)

在训练初期, 由于参数是随机初始化的, 梯度往往非常大. 如果此时学习率较大, 可能导致模型震荡. 
- *原理*: 在最初的若干个迭代步中, 将学习率从一个极小值逐渐线性增加到预设的初始学习率. 
- *作用*: 使模型在训练初期更平稳地探索参数空间. 

常用方法是*逐渐预热* (Gradual Warmup), 即从 $alpha_0$ 线性增加到 $alpha_1$, 然后再进行学习率衰减. 

==== 周期性学习率调整 (Cyclical Learning Rate)

不同于传统的单调递减策略, 周期性调整让学习率在一定范围内循环波动, 从而使模型具有更好的探索能力. 

- *循环学习率 (Cyclical Learning Rate, CLR)*: 
  设置一个学习率范围 $[alpha_"min", alpha_"max"]$, 让学习率在两个边界之间周期性地线性变化. 这种方法可以帮助模型跳出鞍点或局部最优解, 且不需要像固定学习率那样反复试验最优初始值.  \
  例如三角循环学习率可以将最大值线性缩小, 也可以每次保持不变. 

- *带热重启的随机梯度下降 (SGDR)*: 
  SGDR (Stochastic Gradient Descent with Warm Restarts) 常与 *余弦退火 (Cosine Annealing)* 配合使用. 其核心在于: 
  - *退火阶段*: 学习率按余弦函数平滑下降至最小值. 
    $ alpha_t = alpha_"min"^i + 1/2 (alpha_"max"^i - alpha_"min"^i) (1 + cos(pi t / T_i)) $
  - *热重启 (Warm Restart)*: 当学习率下降到最小值后, 立即将其重置为初始的最大值, 开始下一个周期的训练. 
  
- *作用与优势*: 
  1. *跳出局部最优*: 热重启时学习率突然增大, 产生的“震荡”能帮助模型从当前的局部最优坑穴中跳出, 去寻找更好的平坦最小值. 
  2. *训练稳定性*: 余弦退火保证了在一个周期内部, 模型能平滑地向最优解收敛. 
  3. *效率*: 通常能比固定学习率策略在更短的 Epoch 内达到更好的精度. 

==== 自适应学习率 (Adaptive Learning Rate)

通过计算历史梯度信息来为每个参数单独设置学习率. 
- *AdaGrad*: 累积历史梯度的平方和, 对频繁更新的参数设置较小学习率. 
- *RMSprop*: 在 AdaGrad 基础上引入衰减系数, 只考虑近期梯度的信息, 解决后期学习率过早消失的问题. 
- *Adam*: 结合了动量 (Momentum) 和 RMSprop, 是目前工业界最常用的自适应优化算法. 

前两者的参数更新差值都是用下式计算得到 $ Delta theta_t = - alpha / sqrt(G_t + epsilon) dot.o g_t $
其中, 
- AdaGrad 通过计算梯度平方累计值, 即 $ G_t = G_(t - 1) + g_t dot.o g_t $
- RMSprop 则在 AdaGrad 的基础上引入了衰减系数, *指数衰减移动平均*, 即 $ G_t = beta G_(t - 1) + (1 - beta) g_t dot.o g_t $

=== 梯度估计修正

在小批量梯度下降中, 由于采样的随机性, 梯度的估计往往包含噪声. 通过引入历史梯度的信息, 可以有效平滑参数更新轨迹, 加速收敛. 

==== 动量法 (Momentum)

动量法通过引入一个动量项 (速度) 来积累之前的梯度信息. 
- *计算公式*: 
  $ v_t = rho v_(t-1) + g_t $
  $ theta_(t+1) = theta_t - alpha v_t $
  其中 $rho$ 为动量因子 (通常设为 0.9), $v_t$ 是对梯度的指数加权平均. 
- *作用*: 在梯度方向一致的维度上加速, 在梯度方向频繁震荡的维度上减速, 从而减少震荡, 加快收敛. 

==== Nesterov 加速梯度 (Nesterov Accelerated Gradient, NAG)

NAG 是对动量法的改进, 其核心思想是“瞻前顾后”, 即在当前位置先按照动量方向“走一步”, 再计算该位置的梯度. 
- *更新规则*: 
  $ v_t = rho v_(t-1) + g_t (theta_t - alpha rho v_(t-1)) $
  $ theta_(t+1) = theta_t - alpha v_t $
- *区别*: 动量法计算的是当前位置的梯度, 而 NAG 计算的是预估未来位置的梯度. 这使得 NAG 具有更好的预见性, 能防止更新过头. 

==== Adam 算法 (Adaptive Moment Estimation)

$ "Adam" approx "Momentum" + "RMSprop" $

Adam 结合了动量法和自适应学习率 (RMSprop) 的优点, 是目前最常用的优化算法之一. 
- *核心公式*: 
  1. 计算梯度的一阶矩 (动量) 和二阶矩 (未中心化的方差): 
     $ M_t = beta_1 M_(t-1) + (1 - beta_1) g_t $
     $ G_t = beta_2 G_(t-1) + (1 - beta_2) g_t dot.o g_t $
  2. 偏差修正 (解决初始阶段 $M_t, G_t$ 偏向 0 的问题): 
     $ hat(M)_t = M_t / (1 - beta_1^t), quad hat(G)_t = G_t / (1 - beta_2^t) $
  3. 参数更新: 
     $ theta_(t+1) = theta_t - alpha / sqrt(hat(G)_t + epsilon) hat(M)_t $
- *特点*: 能够为不同的参数自适应地调节学习率, 同时利用动量平滑梯度, 通常对超参数不敏感. 

==== 梯度截断 (Gradient Clipping)

梯度截断是一种防止梯度爆炸的简单而有效的策略. 其核心思想是当梯度的范数超过某个阈值时, 将其截断到该阈值. 

$ g_t = "clip"(g_t, -c, c) $

=== 参数初始化方法对比

参数初始化的主要目的是维持神经网络层与层之间信号的方差, 避免梯度消失或爆炸. 

#figure(
  table(
    columns: (auto, 2fr, 1fr, 2.5fr),
    align: center + horizon,
    [*初始化方法*], [*核心公式 / 分布*], [*适用场景*], [*主要特点*],
    [固定方差], [$W ~ cal(N)(0, sigma^2)$ \ 或 $U(-r, r)$], [小型网络, 浅层模型], [这种方法通常从一个固定方差的分布 (如高斯分布或均匀分布) 中采样. 简单但易导致深层梯度不稳定],
    [Xavier (Glorot)], [$sigma^2 = 2 / (n_"in" + n_"out")$], [Sigmoid, Tanh \ 等线性/对称激活], [保持输入输出方差一致, 其中 $n_"in"$ 和 $n_"out"$ 分别是当前层的输入和输出维度. ],
    [He (Kaiming)], [$sigma^2 = 2 / n_"in"$], [ReLU, Leaky ReLU], [由于 ReLU 激活函数会将一半的输入设为 0, 导致方差减半, 因此 He 初始化将方差扩大两倍. 补偿了 ReLU 带来的方差减半],
    [正交初始化], [$W W^T = I$], [RNN, 极深层 CNN], [保持梯度范数, 缓解长距离依赖问题]
  ),
  caption: [常见参数初始化方法总结],
)

=== 数据预处理 (Data Preprocessing)

虽然神经网络具有一定的尺度不变性, 但输入特征尺度差异过大会导致损失函数的等高线呈椭球状, 增加优化难度. 通过预处理, 可以使各个维度的特征具有相似的取值区间, 从而加速收敛. 

==== 最小最大归一化 (Min-Max Normalization)

将特征缩放到固定的区间 (通常是 $[0, 1]$). 
- *计算公式*: $hat(x) = (x - x_min) / (x_max - x_min)$
- *特点*: 对原始数据的分布影响较小, 但在有离群值 (Outliers) 时效果较差, 因为极大值会压缩正常数据的取值范围. 

==== 标准化 (Standardization / Z-Score Normalization)

将特征转换为均值为 0、方差为 1 的分布. 
- *计算公式*: $hat(x) = (x - mu) / sigma$
- *特点*: 最常用的预处理方法. 它不仅能处理量纲不一的问题, 还能使特征分布更符合激活函数 (如 $tanh$) 的非饱和区, 有利于梯度传播. 

==== 白化 (Whitening)

白化是一种更高级的预处理方法, 旨在消除特征之间的相关性. 
- *核心操作*: 
  1. 先进行标准化, 使均值为 0. 
  2. 利用主成分分析 (PCA) 旋转坐标轴, 消除冗余相关性. 
  3. 对每个维度进行缩放, 使特征协方差矩阵为单位矩阵 $I$. 
- *作用*: 白化可以使输入数据在空间中分布更“圆”, 进一步降低特征间的冗余, 但计算开销较大. 

=== 逐层归一化 (Layer-wise Normalization)

在深度神经网络中, 前层参数的更新会改变后层输入的分布, 这种现象称为 *内部协变量偏移 (Internal Covariate Shift)*. 逐层归一化通过将各层神经元的净输入或激活值转换到统一的分布上, 极大地改善了深层网络的训练稳定性. 

- *加速收敛*: 允许使用更大的学习率, 而不必担心梯度消失或爆炸. 
- *降低敏感性*: 减轻了模型对参数初始化方案的依赖. 
- *正则化效果*: 引入了一定的随机噪声 (尤其在批量归一化中), 有助于提高模型的泛化能力. 

对于每一层的净输入 $z$, 归一化操作通常包含两个步骤: 
1. *标准化*: 将 $z$ 变换为均值为 0、方差为 1 的分布. 
   $ hat(z) = (z - mu) / sqrt(sigma^2 + epsilon) $
2. *再参数化 (Scaling and Shifting)*: 为了恢复网络的表达能力, 引入可学习的参数 $gamma$ 和 $beta$:
   $ y = gamma hat(z) + beta $
   这样模型可以自动学习是否需要还原原始分布. 

#figure(
  table(
    columns: (auto, 2fr, 2fr),
    align: center + horizon,
    [*方法*], [*归一化对象 (统计量计算范围)*], [*适用场景*],
    [批量归一化 (Batch Norm)], [在*小批量 (Batch)* 维度上计算均值和方差. ], [卷积神经网络 (CNN), \ 计算机视觉任务],
    [层归一化 (Layer Norm)], [在*单个样本的所有特征*维度上计算均值和方差. ], [循环神经网络 (RNN), \ Transformer (NLP任务)],
  ),
  caption: [批量归一化与层归一化的区别],
)

重点理解: BN 与 LN 的区别
- *Batch Normalization (BN)*: 强依赖于 Batch Size. 在训练时记录全局均值和方差供测试时使用. 对于动态网络 (如 RNN) 或小 Batch 场景效果较差. 
- *Layer Normalization (LN)*: 均值和方差仅取决于当前单个样本. 它不依赖 Batch 大小, 在处理变长序列数据 (如自然语言处理) 时表现出卓越的稳定性. 

=== 超参数优化 (Hyperparameter Optimization)

超参数是定义模型结构和训练算法控制权标的参数, 无法通过梯度下降自动更新. 超参数优化的目标是寻找一组配置, 使模型在验证集上的性能达到最优. 

#figure(
  table(
    columns: (1fr, 2.5fr, 1.5fr),
    inset: 7pt,
    align: (center + horizon, left + horizon, center + horizon),
    fill: (x, y) => if y == 0 { gray.lighten(80%) },
    [*方法*], [*核心原理*], [*评价*],
    [网格与随机搜索 (Grid/Random)], [在空间中按步长或随机采样尝试. ], [随机搜索效率通常高于网格. ],
    [贝叶斯优化 (Bayesian Opt)], [利用已评估点构建概率模型 (如高斯过程), 预测并平衡“探索”与“利用”. ], [自适应强, 实验次数少. ],
    [动态资源分配 (Hyperband)], [提前终止表现不佳的超参数配置 (早停), 将资源倾斜给潜力模型. ], [高效利用计算资源. ],
    [神经架构搜索 (NAS)], [利用子网络性能作为反馈, 训练控制器自动设计模型结构. ], [高度自动化 (元学习). ]
  ),
  caption: [常见超参数优化方法总结],
)

== 网络正则化核心方法

正则化通过对模型施加约束来限制其复杂度. 对于表达能力极强的深度网络, 正则化是确保模型从“拟合数据”走向“理解规律”的关键. 

=== $ell_1$ 与 $ell_2$ 正则化

这是最基础的正则化技术, 通过在损失函数中引入参数范数惩罚项来约束搜索空间. 

- *$ell_1$ 正则化 (Lasso)*: 惩罚项为参数绝对值之和 $lambda ||theta||_1$. 
  - *特性*: 倾向于产生*稀疏解* (许多参数变为 0), 具有自动特征选择的功能. 
  - *几何形状*: 在参数空间中呈菱形. 
- *$ell_2$ 正则化 (Ridge)*: 惩罚项为参数平方和 $1/2 lambda ||theta||_2^2$. 
  - *特性*: 使权重普遍变小且分散 (*权重衰减*), 防止模型过度依赖个别特征. 
  - *几何形状*: 在参数空间中呈圆形. 

#figure(
  table(
    columns: (1fr, 1.5fr, 1.5fr),
    inset: 6pt,
    align: center + horizon,
    fill: (x, y) => if y == 0 { gray.lighten(80%) },
    [*特性*], [*$ell_1$ 正则化*], [*$ell_2$ 正则化*],
    [核心约束], [参数绝对值之和], [参数平方和],
    [解的性质], [稀疏解 (特征选择) ], [平滑解 (权重压缩) ],
    [几何形状], [菱形 (易交在轴上) ], [圆形 (各向同性) ]
  ),
  caption: [L1 与 L2 正则化对比]
)



=== 权重衰减 (Weight Decay)

权重衰减在每次迭代时按比例缩减参数值: $theta_t arrow.l (1 - beta) theta_(t-1) - alpha g_t$. 
- *与 $ell_2$ 的关系*: 在标准 SGD 下, $ell_2$ 正则化等价于权重衰减. 但在 Adam 等自适应优化器中, 两者的实现逻辑不同, 需区分对待 (如使用 AdamW 优化器). 

=== 丢弃法 (Dropout)

Dropout 通过在训练时随机“关闭”一部分神经元 (概率为 $p$) 来增强模型的鲁棒性. 

- *集成学习视角*: 每次丢弃相当于采样了一个不同的子网络, 最终测试阶段相当于对海量共享参数的子网络进行“模型集成”. 
- *贝叶斯视角*: 被视为对参数后验分布的一种近似贝叶斯推断 (MC Dropout), 赋予了模型不确定性估计的能力. 
- *注意*: 在 RNN 中, 不能直接在时间步的循环连接上使用 Dropout, 否则会破坏长程记忆; 通常仅应用于非循环连接. 

=== 标签平滑 (Label Smoothing)

针对模型“过分自信”导致的过拟合, 将 one-hot 硬标签转换为软标签. 
- *公式*: 将 $[0, 0, 1]$ 转换为 $[epsilon / (K-1), epsilon / (K-1), 1 - epsilon]$. 
- *作用*: 防止模型将正确类别的概率强推向 1, 抑制权重过大, 在有噪声的数据集上表现尤为稳健. 

== 考点预测与习题分析

